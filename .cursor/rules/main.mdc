---
description: 
globs: 
alwaysApply: false
---
Okay, this is a significantly more complex project than the initial FPS game, integrating blockchain, NFTs, real-time gaming, betting, and social features. A 10-day timeline for the entire described scope is highly unrealistic for any team, let alone potentially a single developer guided by AI. Building robust, secure Solana programs, scalable game servers, and a feature-rich frontend takes considerable time, testing, and auditing.

However, I can provide a detailed, phased plan focusing on best practices, scalability, and the Solana architecture, breaking it down into manageable parts. This plan will assume you need to build this efficiently, prioritizing core functionality first. We will use Next.js for the frontend and API routes, leveraging its hybrid capabilities.

Core Architectural Principles:

Solana as Source of Truth (for Value/Ownership): Escrow state, SOL balances, NFT ownership, core player stats (W/L potentially), and profile authority reside on Solana.

Off-Chain for Speed & Flexibility: Real-time game logic, matchmaking coordination, chat, user sessions, feed data, and cached data will be handled by off-chain services (Next.js API routes, dedicated game servers, potentially Redis/Postgres).

Game Servers as Trusted Oracles: Off-chain game servers determine match outcomes and are trusted to interact with Solana programs to release escrow and trigger result recording. Protecting the server's wallet/authority is paramount.

Anchor Framework: Use Anchor for Solana program development to accelerate development and reduce boilerplate.

Modularity: Build components (Platform API, Matchmaking, Game Server Manager, Solana Programs, NFT Service) as modularly as possible.

Let's start with Part 1, focusing on the absolute foundation: the Next.js platform, wallet integration, basic user system, and the initial Solana program structures.

Part 1: Platform Foundation & Solana Core Setup

Objective: Establish the Next.js application shell, connect to Solana wallets, set up basic user handling (off-chain initially linked to wallet), and define/deploy foundational Solana programs for profiles and escrow.

Phase 1: Next.js Platform & Wallet Integration Setup

Goal: Create the basic web application structure, integrate Solana wallet connectivity, and set up initial off-chain user handling.

1.1 Project Infrastructure (Monorepo Recommended)

Step 1: Initialize Monorepo: Use pnpm, yarn workspaces, or nx/turborepo. Create packages: apps/web (Next.js app), packages/solana-programs (Anchor project), packages/ui (shared React components), packages/shared-types (common TS types).

# Example using pnpm
mkdir solana-gaming-platform && cd solana-gaming-platform
pnpm init
# Create pnpm-workspace.yaml
# packages:
#  - 'apps/*'
#  - 'packages/*'
mkdir apps packages
# ... initialize packages inside ...


Step 2: Initialize Next.js App (apps/web): Use pnpm create next-app apps/web (or yarn/npx equivalent). Choose TypeScript. Configure ESLint, Prettier.

Step 3: Setup Shared UI (packages/ui): Initialize a basic React component library package. Storybook recommended for component development.

Step 4: Setup Shared Types (packages/shared-types): Initialize a TypeScript package for interfaces/types used across frontend, backend (API routes), and potentially Solana program interfaces (using tools like anchor-ts).

Step 5: Configure TS Paths/Refs: Set up TypeScript project references or path aliases in tsconfig.json files across the monorepo for easy cross-package imports (@/ui, @/shared-types, etc.).

Why: Organizes code logically, facilitates code sharing (UI components, types), simplifies dependency management, and enables unified build/test processes, crucial for a complex project.

Unit Test: Verify monorepo tool recognizes workspaces. Import a shared type from @/shared-types into the Next.js app (apps/web). Run tsc --noEmit from the root; verify it compiles without resolution errors. Run basic Next.js dev server (pnpm --filter web dev).

Troubleshooting: TS path resolution errors (check tsconfig.json baseUrl, paths, references). Monorepo tool setup issues (consult tool docs).

STOP & CHECK: Monorepo structure is functional, Next.js app runs, shared types/UI packages are set up, and basic cross-package imports work.

1.2 UI Shell & Responsiveness

Step 1: Choose UI Framework/Library: Select a UI component library compatible with React/Next.js (e.g., Tailwind CSS + Headless UI, Chakra UI, MUI, Ant Design) or build custom components in packages/ui. Recommendation: Tailwind CSS offers high flexibility for custom, responsive designs.

Step 2: Create Layout Component: In apps/web, create a main Layout.tsx component including common elements: Header (Navbar), Footer, main content area. Include basic navigation links (Home, Games, Profile, Marketplace - placeholders).

Step 3: Implement Responsive Design: Use CSS media queries (directly or via Tailwind's responsive modifiers like md:, lg:) within the Layout and core UI components to ensure usability on different screen sizes (desktop, tablet, mobile). Test using browser developer tools' responsive mode. Focus on navigation, readability, and core interaction elements first.

Why: Provides a consistent structure for the application and ensures a baseline level of usability across devices, essential for a modern web platform, especially for the marketplace aspect.

Unit Test: View the basic Next.js app in browser dev tools across different device presets (iPhone, iPad, Desktop). Verify the layout adapts appropriately (e.g., navbar collapses into a hamburger menu, content reflows).

Troubleshooting: CSS conflicts, unresponsive elements (check media queries, flexbox/grid properties), layout shifts.

STOP & CHECK: Basic responsive application shell with header/footer/navigation exists and adapts reasonably to different screen sizes.

1.3 Solana Wallet Integration (@solana/wallet-adapter)

Step 1: Install Dependencies: In apps/web, install wallet adapter packages:

pnpm --filter web add @solana/wallet-adapter-react @solana/wallet-adapter-react-ui @solana/wallet-adapter-base @solana/web3.js @solana/wallet-adapter-wallets
# Also install CSS for the modal:
pnpm --filter web add @solana/wallet-adapter-react-ui/styles.css
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Bash
IGNORE_WHEN_COPYING_END

Step 2: Create Wallet Context Provider: Create a wrapper component (e.g., components/WalletContextProvider.tsx) that sets up the required contexts from the library.

// components/WalletContextProvider.tsx (Simplified)
import React, { FC, useMemo } from 'react';
import { ConnectionProvider, WalletProvider } from '@solana/wallet-adapter-react';
import { WalletAdapterNetwork } from '@solana/wallet-adapter-base';
import { WalletModalProvider } from '@solana/wallet-adapter-react-ui';
import { clusterApiUrl } from '@solana/web3.js';
import { PhantomWalletAdapter, /* other adapters */ } from '@solana/wallet-adapter-wallets';
require('@solana/wallet-adapter-react-ui/styles.css'); // Import styles

export const WalletContextProvider: FC<{ children: React.ReactNode }> = ({ children }) => {
    const network = WalletAdapterNetwork.Devnet; // Or Mainnet-beta / Testnet
    const endpoint = useMemo(() => clusterApiUrl(network), [network]);
    const wallets = useMemo(() => [new PhantomWalletAdapter()], [network]);

    return (
        <ConnectionProvider endpoint={endpoint}>
            <WalletProvider wallets={wallets} autoConnect>
                <WalletModalProvider>{children}</WalletModalProvider>
            </WalletProvider>
        </ConnectionProvider>
    );
};
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
TypeScript
IGNORE_WHEN_COPYING_END

Step 3: Wrap Application: In apps/web/pages/_app.tsx, wrap the main Component with WalletContextProvider.

Step 4: Add Connect Button: In your Header component, use the UI component provided: import { WalletMultiButton } from '@solana/wallet-adapter-react-ui'; ... <WalletMultiButton />. This button handles connect/disconnect flow and displays the connected wallet address.

Step 5: Access Wallet State: Use hooks in components where needed: import { useConnection, useWallet } from '@solana/wallet-adapter-react'; const { connection } = useConnection(); const { publicKey, signTransaction, sendTransaction } = useWallet(); if (publicKey) { /* Display user info, enable features */ }.

Why: Provides the core mechanism for users to connect their Solana wallets (Phantom, Solflare, etc.) to the web app, enabling authentication (proving ownership of address), signing transactions (placing bets, buying NFTs), and interacting with Solana programs. @solana/wallet-adapter is the standard library for this.

Tip: Start with Devnet for development. Ensure RPC endpoint (endpoint) is reliable (consider using custom RPC providers like QuickNode/Alchemy later for better performance/reliability).

Unit Test: Run the Next.js app. Verify the WalletMultiButton appears. Click it; verify the wallet selection modal appears. Connect a wallet (Phantom Devnet recommended). Verify the button updates to show the connected address and provides a disconnect option. Check browser console for connection errors. Access publicKey in a component and verify it logs the correct address when connected.

Troubleshooting: Wallet modal doesn't appear (check CSS import, ensure providers wrap correctly). Connection errors (check network/endpoint URL, wallet settings). publicKey is null (ensure wallet connected successfully).

STOP & CHECK: Users can connect and disconnect their Solana wallets to the application using the Wallet Adapter button, and the connected public key is accessible within React components.

1.4 Basic User Authentication/Handling (Off-Chain + Wallet)

Step 1: Strategy: Use wallet connection as the primary "login". Link the wallet's public key to an off-chain user record for storing data not suitable for the on-chain profile (e.g., email for notifications (optional), user preferences, private message relations).

Step 2: Database Schema (Off-Chain): Use PostgreSQL (via Prisma ORM recommended for type safety) or MongoDB. Create a User table/collection : id (UUID/Serial), walletAddress (String, Unique, Indexed), username (String, Optional), createdAt (Timestamp), lastLogin (Timestamp).

Step 3: API Route for Sign-In/Registration: Create a Next.js API route (e.g., pages/api/auth/wallet-login.ts).

Client: When useWallet hook shows publicKey is available and not previously authenticated in this session, client calls this API route, potentially sending the publicKey string.

Server (API Route):

Receive walletAddress. Validate it's a valid Solana address.

Check if user exists in DB: prisma.user.findUnique({ where: { walletAddress } }).

If exists: Update lastLogin, return user data (e.g., ID, username).

If not exists: Create new user: prisma.user.create({ data: { walletAddress } }). Return new user data.

Use a session management solution (like next-auth with a custom wallet provider, or iron-session) to create a secure session cookie for the client after successful login/registration, storing the off-chain user ID.

Step 4: Client Session Management: Use a React Context or state management library (Zustand, Jotai) to store the authenticated user state (off-chain ID, wallet address, username) fetched after wallet connection and API call. Protect client-side routes/features based on this authenticated state.

Why: Links the ephemeral wallet connection to a persistent off-chain user record. Allows storing traditional web application data associated with the user without putting everything on-chain. Session cookies provide standard web authentication flow after initial wallet verification.

Tip: While wallet connection proves ownership at that moment, session cookies maintain login state across page loads without requiring constant wallet interaction. Consider adding a "sign message" step during login for stronger verification that the user currently controls the wallet keys.

Unit Test: Connect wallet. Verify client calls login API route. Check server logs: verify API receives address, finds or creates user in DB (check DB directly). Verify API response includes user ID. Verify session cookie set in browser. Refresh page; verify client state management restores logged-in state using session. Disconnect wallet; verify logged-in state is cleared.

Troubleshooting: API route errors (check DB connection, Prisma client generation, request parsing). Session not persisting (check cookie settings, session library configuration). User not found/created correctly (check DB query logic).

STOP & CHECK: Wallet connection triggers a backend check/creation of an associated off-chain user record, establishing a persistent session and providing an off-chain user ID linked to the wallet address.

Phase 2: Solana Core Program & Account Structures (Anchor)

Goal: Define, develop (using Anchor), and deploy the initial versions of the core Solana programs and account structures needed for player profiles and match escrow.

2.1 Anchor Project Setup (packages/solana-programs)

Step 1: Install Anchor CLI: Follow official Anchor documentation (https://www.anchor-lang.com/) to install the CLI tool.

Step 2: Initialize Anchor Project: Navigate to packages/solana-programs and run anchor init solana_gaming_platform --javascript. This creates the necessary directory structure (programs/, tests/, migrations/, Anchor.toml, package.json).

Step 3: Configure Anchor.toml:

Set [provider] cluster initially to devnet. Define [provider] wallet pointing to your local filesystem wallet keypair used for deployment/testing (e.g., ~/.config/solana/id.json).

List your program(s) under [programs.devnet].

Step 4: Install JS Dependencies: Run pnpm install (or yarn/npm) inside packages/solana-programs to install @coral-xyz/anchor, @solana/web3.js, etc.

Step 5: Link Shared Types (Optional but Recommended): If defining account structures in @/shared-types, configure packages/solana-programs/tsconfig.json to reference or import them, keeping definitions consistent. Alternatively, use anchor-ts later to generate TS types from Rust code.

Why: Anchor framework significantly simplifies Solana program development by handling serialization/deserialization, instruction parsing, account validation boilerplate, and providing testing/deployment tools. Setting up the project structure correctly is the first step.

Unit Test: Run anchor build in packages/solana-programs. Verify it compiles the default starter program without errors. Run anchor test (this will run the default JS tests); verify they pass against a local validator (Anchor tries to start one automatically if needed).

Troubleshooting: Anchor installation issues (check Rust/Cargo versions, Solana tool suite). Build errors (check Rust code, Anchor.toml syntax). Test failures (check local validator status, test script logic).

STOP & CHECK: Anchor project initialized, configured for Devnet, default program builds and tests successfully.

2.2 Player Profile Program (V1 - On-Chain Data)

Step 1: Define Account Struct (programs/solana-gaming-platform/src/lib.rs): Define the structure for storing player data on-chain. Consider Solana account size limits and rent costs.

// programs/solana-gaming-platform/src/lib.rs
use anchor_lang::prelude::*;
// ... other imports

#[account]
#[derive(Default)]
pub struct PlayerProfile {
    pub authority: Pubkey, // The wallet that controls this profile
    pub username: String, // Keep short to manage size, e.g., max 32 chars
    pub avatar_uri: String, // URI to image/metadata, max e.g., 100 chars
    pub overall_wins: u64,
    pub overall_losses: u64,
    // Per-game stats might need separate accounts or careful sizing
    // pub game1_wins: u64,
    // pub game1_losses: u64,
    // ... (Consider account size limits!)
    pub bump: u8, // If using PDA
}

// Define max sizes for strings to calculate space needed
const USERNAME_MAX_LEN: usize = 32;
const URI_MAX_LEN: usize = 100;
// Calculate space: 8 (discriminator) + 32 (authority) + 4+USERNAME_MAX_LEN + 4+URI_MAX_LEN + 8 + 8 + 1 (bump) ... Add space for other stats cautiously
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Rust
IGNORE_WHEN_COPYING_END

Step 2: Define Instructions Contexts:

CreatePlayerProfile: Takes username, avatar_uri. Requires payer (signer, funds account creation), player_profile account (derived PDA, init), authority (signer, wallet creating profile), system_program. Profile account should likely be a PDA seeded by ["player_profile", authority.key().as_ref()] for easy lookup.

UpdatePlayerAvatar: Takes new_avatar_uri. Requires player_profile account (mut), authority (signer, must match profile.authority).

UpdateStats (Internal/Trusted): Takes wins_increment, losses_increment. Requires player_profile account (mut), game_server_authority (signer - needs careful design, maybe program authority?). Initially, this might only be callable by the program's upgrade authority or a designated admin/server key.

Step 3: Implement Instruction Logic (Rust): Write the Rust functions for each instruction, performing validation (string lengths, authority checks) and updating the account data. Use Anchor constraints (#[account(signer)], #[account(mut)], #[account(init, payer = ...)], #[account(seeds = ..., bump)], #[account(constraint = ...)]).

Step 4: Build & Deploy: Run anchor build, anchor deploy. Note the deployed program ID. Update Anchor.toml and lib.rs (declare_id!) with the new program ID.

Step 5: Basic JS Tests (tests/solana-gaming-platform.ts): Write Anchor JS tests to:

Create a new keypair (simulating user wallet).

Airdrop SOL to it.

Call create_profile instruction using the program client. Verify account created with correct data (fetch account state).

Call update_player_avatar. Verify URI updated.

Attempt to call update_player_avatar with wrong authority; verify transaction fails.

Call update_stats (if implemented with testable authority); verify stats updated.

Why: Creates the on-chain foundation for player identity and core stats. Storing this data on Solana makes it publicly verifiable and associates it directly with the player's wallet authority. Using PDAs makes accounts discoverable. Careful size management is essential due to rent costs.

Tip: Start with minimal fields in PlayerProfile (authority, counters, bump). Add optional fields like username/URI later or store them off-chain initially if size is a concern. Stat updates need a secure mechanism – likely called by a trusted server or another program.

Unit Test: Run anchor test. Verify all JS tests pass: profile created, URI updated, authority checks enforced, stats updated correctly. Manually inspect account data on Devnet using Solana Explorer after running tests. Check account size/rent exemption.

Troubleshooting: Rust compilation errors (check syntax, types, lifetimes). Anchor constraint violations (check signer/mut/init attributes, seeds/bump logic). Account size errors (reduce string lengths, remove fields, consider splitting into multiple accounts). Runtime errors (check instruction logic, authority checks). JS test setup (wallet funding, program client initialization).

STOP & CHECK: Basic Player Profile Solana program is deployed to Devnet, allowing creation and controlled updates (URI by owner, stats by trusted authority) via JS tests. Account structure is defined, considering size limitations.

2.3 Match Escrow Program (V1 - SOL Betting)

Step 1: Define Escrow Account Struct (lib.rs):

#[account]
#[derive(Default)]
pub struct MatchEscrow {
    pub player_one: Pubkey,
    pub player_two: Pubkey,
    pub game_id: String, // Identifier for the specific game type/rules
    pub match_id: u64, // Unique ID for this specific match instance
    pub bet_amount: u64, // Lamports per player
    pub status: MatchStatus, // Enum: Pending, Active, PlayerOneWon, PlayerTwoWon, Draw, Disputed
    pub escrow_vault: Pubkey, // PDA for the SOL vault
    pub authority: Pubkey, // Trusted game server/admin key that can release funds
    pub bump: u8, // PDA bump for escrow account
    pub vault_bump: u8, // PDA bump for vault account
}

#[derive(AnchorSerialize, AnchorDeserialize, Clone, PartialEq, Eq, Default)]
pub enum MatchStatus { #[default] Pending, Active, PlayerOneWon, PlayerTwoWon, Draw, Disputed }

// Define reasonable size for game_id String
const GAME_ID_MAX_LEN: usize = 16;
// Calculate space...
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Rust
IGNORE_WHEN_COPYING_END

Step 2: Define Instructions Contexts:

InitializeEscrow: Takes game_id, match_id, bet_amount, player_two_pubkey. Requires player_one (signer, payer), player_two (passed in), match_escrow account (derived PDA seeded by e.g., ["match_escrow", player_one.key().as_ref(), player_two.key().as_ref(), match_id.to_le_bytes().as_ref()], init), escrow_vault (derived PDA seeded by ["escrow_vault", match_escrow.key().as_ref()], init), authority (passed in, e.g., server's pubkey), system_program. Player One calls this and transfers bet_amount SOL into the escrow_vault. Sets status to Pending.

JoinEscrow: Requires player_two (signer, payer), match_escrow account (mut, check status is Pending, check player_two matches), escrow_vault (mut), system_program. Player Two calls this and transfers bet_amount SOL into the escrow_vault. Sets status to Active.

ReleaseEscrow: Takes winner_pubkey. Requires authority (signer, must match escrow.authority), match_escrow account (mut, check status Active), escrow_vault (mut), winner_account (recipient, mut), system_program. Checks winner_pubkey is player one or two. Transfers total SOL (2 * bet_amount) from escrow_vault PDA to winner_account using CPI (Cross-Program Invocation) to System Program transfer, signing with vault PDA seeds. Closes escrow_vault and match_escrow accounts, returning rent to authority. Updates status. (Handle draws/disputes later).

Step 3: Implement Instruction Logic (Rust): Write Rust functions. Use anchor_lang::system_program::transfer for SOL transfers. Use anchor_lang::solana_program::program::invoke_signed for transferring from the PDA vault. Implement status checks (require_eq!).

Step 4: Build & Deploy: anchor build, anchor deploy. Update program ID.

Step 5: JS Tests (tests/...):

Create keypairs for P1, P2, Authority. Airdrop SOL.

P1 calls initialize_escrow. Verify escrow account created, status Pending, vault has 1x bet amount.

P2 calls join_escrow. Verify status Active, vault has 2x bet amount.

Authority calls release_escrow specifying P1 as winner. Verify vault balance transferred to P1's wallet, escrow/vault accounts closed.

Test authority checks (P1 cannot call release_escrow). Test status checks (cannot join if Active, cannot release if Pending).

Why: Creates a trustless on-chain mechanism to hold player bets. Funds are only released based on predefined rules (match outcome determined by trusted authority/server). PDAs ensure programmatic control over the escrowed funds.

Tip: Start with SOL escrow first. Token (e.g., USDC) escrow adds complexity with SPL Token program interactions and token accounts. Closing accounts recovers rent, which is important. The authority key is critical – secure it!

Unit Test: Run anchor test. Verify all test cases pass: init, join, release to correct winner, authority checks, status checks, vault balances correct at each step, accounts closed correctly. Inspect transactions on Solana Explorer.

Troubleshooting: PDA address derivation issues (check seeds, bump). CPI transfer errors (check account mut, signing seeds, lamport amounts). Authority constraint failures. Rent calculation/account closing issues. Compute unit limits if logic becomes complex.

STOP & CHECK: Basic Match Escrow Solana program deployed to Devnet. Allows two players to deposit SOL into a PDA vault, which can then be released to the designated winner only by a predefined authority keypair.

This completes Part 1. We now have:

A basic Next.js web application structure.

Users can connect Solana wallets.

Wallet connections are linked to basic off-chain user records.

An on-chain Player Profile program (V1) deployed to Devnet.

An on-chain SOL Match Escrow program (V1) deployed to Devnet.

Okay, here is Part 2 of the detailed plan for the Solana Gaming Platform, focusing on integrating the game servers, implementing the core gameplay loop with escrow interaction, adapting the first game, and laying the foundation for the NFT system.

Part 2: Game Integration, Gameplay Loop & NFT Foundation

Objective: Integrate the off-chain game server architecture, implement the end-to-end gameplay loop including Solana escrow interactions, adapt the first game (1v1 FPS), and define the basic structure for the player NFT system.

Phase 3: Off-Chain Game Server Infrastructure

Goal: Establish the backend system responsible for spawning, managing, and communicating with isolated game server instances (like the 1v1 FPS duel). This typically runs separately from the main Next.js web application but communicates with it (e.g., via API or Redis).

3.1 Game Server Manager (Spawner) Service

Step 1: Create New Service: In the monorepo, create a new package (e.g., packages/game-server-manager). This will be a standalone Node.js application (using JavaScript). Install necessary dependencies (redis, potentially a Node.js framework like Fastify or Express if it needs an API).

Step 2: Implement Spawning Logic: Using Node.js child_process.fork(), write a function spawnGameInstance(gameType, matchConfig):

Determine path to the specific game server script (e.g., ../server/src/gameInstance_fps.js).

Allocate a unique available port number (manage a pool or use OS assignment with care).

Generate a unique matchId.

Prepare command-line args/env vars for the child process: port, matchId, potentially expected player IDs, gameType, reference to the authority keypair path (for Solana interactions).

Execute fork(): const child = fork(scriptPath, args, { stdio: 'pipe' /* Capture stdout/err */ });. Store reference to child process object, mapped by matchId.

Step 3: Implement Process Monitoring: Attach listeners to the child process object:

child.on('message', (message) => { /* Handle IPC messages FROM game instance */ }); (For status updates, results).

child.on('error', (err) => { /* Log fork error */ });.

child.on('exit', (code, signal) => { handleGameInstanceExit(matchId, code, signal); }); (Crucial for cleanup and crash detection).

Step 4: Registry Integration (Redis): Connect this service to Redis. Implement functions:

registerAvailableServer(serverId, port, ip): Adds server ID to available_servers:<gameType> set and details to server_details:<serverId> hash. Called by game instance via IPC or API upon startup.

allocateServer(gameType): Pops a server ID from available_servers:<gameType>, removes details, returns connection info. Called by matchmaking logic.

deregisterServer(serverId): Cleans up Redis entries when instance exits cleanly or crashes. Called from handleGameInstanceExit.

Step 5: API for Matchmaking: Expose a simple internal API (or use Redis pub/sub) for the matchmaking service (potentially running within Next.js API routes or separately) to request a new game server allocation: POST /allocate { gameType: 'fps_1v1' } -> Returns { serverId, ip, port, matchId } or error if none available.

Why: Centralizes the logic for launching, tracking, and cleaning up game server processes. Provides a clean interface for matchmaking to get available servers and ensures crashed instances are handled. Using Redis for registry allows multiple manager instances (for HA) or decoupling from matchmaking service.

Tip: Secure this service well, especially if it handles spawning processes or has access to sensitive info. Use environment variables for configuration (Redis URL, paths, etc.). Log extensively.

Unit Test: Start the Manager service. Call its internal allocation function/API; verify it forks a child process (check OS processes), logs the launch, allocates a port, updates Redis registry (check Redis directly), and returns server info. Manually kill the child process; verify the Manager's exit handler detects it, logs the crash, and cleans up Redis registry. Simulate child process sending an IPC message; verify manager receives it.

Troubleshooting: fork() errors (path issues, permissions). Port allocation conflicts. Redis connection/command errors. IPC setup issues. Crash detection/cleanup logic errors.

STOP & CHECK: Game Server Manager service can spawn game instance processes, monitor their exit status, manage their availability via Redis registry, and provide an allocation mechanism for matchmaking.

3.2 Game Instance Communication Protocol

Step 1: Define IPC/API Needs: Determine what information the gameInstance.js process needs to communicate back to the game-server-manager or other central services:

READY: Instance is up, listening, and registered as available.

PLAYER_CONNECTED: A player successfully connected (with ID).

MATCH_STARTED: Both players connected, countdown finished.

MATCH_RESULT: Match ended, includes winner, loser, scores, maybe ELO delta calculation inputs.

ERROR: Internal error occurred.

Step 2: Choose Communication Method:

Node.js IPC: Use process.send(message) from the gameInstance.js child process and child.on('message', ...) in the manager parent process. Simple for direct parent-child communication.

Internal API Calls: Game instance makes HTTP requests to endpoints exposed by the manager or a dedicated results service. More flexible if manager/results service are separate microservices.

Redis Pub/Sub: Game instance publishes events to Redis channels, manager/other services subscribe. Decoupled but less direct request/response.

Recommendation: Start with Node.js IPC (process.send) for simplicity between manager and its direct child. Use internal API calls for reporting results to a persistent storage service.

Step 3: Implement Sending (Game Instance): Inside gameInstance.js, after relevant events, send structured messages: e.g., if (process.send) process.send({ type: 'READY', serverId: myServerId, port: myPort });, process.send({ type: 'MATCH_RESULT', data: matchResultData });.

Step 4: Implement Receiving (Manager): In the manager's child.on('message', ...) handler, use a switch(message.type) to handle different messages appropriately (e.g., log 'READY', trigger result processing on 'MATCH_RESULT').

Why: Establishes a clear communication channel for game instances to report their status and crucial results back to the managing system, enabling proper lifecycle tracking and result processing.

Tip: Keep messages concise. Define message structures clearly (perhaps in @/shared-types). Handle potential errors during sending/receiving.

Unit Test: In game instance, add process.send({ type: 'TEST', value: 123 }) on startup. In manager's message handler, add if (message.type === 'TEST') console.log('Received test message:', message.value);. Launch instance via manager. Verify manager logs "Received test message: 123". Test sending MATCH_RESULT on simulated match end.

Troubleshooting: process.send is undefined (ensure process was launched via fork, not spawn without IPC channel). Messages not received (check listener setup in manager, ensure child process runs long enough to send). Serialization issues if complex objects sent.

STOP & CHECK: A communication protocol (e.g., IPC) exists allowing game instances to report status events (Ready, Result) back to the Game Server Manager.

3.3 Integration with Matchmaking Service

Step 1: Modify Matchmaking Flow: In the matchmaking logic (likely in Next.js API route or separate service, from 4.1.2):

After finding a pair of players (playerA, playerB).

Call the Game Server Manager's allocation API/function (from 3.1.5): const allocation = await requestAllocation('fps_1v1');.

Step 2: Handle Allocation Response:

If successful (allocation contains serverId, ip, port, matchId):

Proceed to notify players with connection details (from 4.1.3).

Optionally, store the matchId and associated player IDs temporarily (e.g., in Redis) so the game instance can verify connecting players later.

If allocation fails (no available servers):

Keep players in the queue (or notify them of failure and requeue). Implement retry logic or notify ops team via monitoring.

Why: Connects the matchmaking decision (who plays) with the infrastructure reality (where they play), ensuring a server is ready before telling players where to connect. Handles the case where no servers are available.

Tip: Make the allocation request idempotent or handle potential race conditions if multiple matchmaking processes run concurrently.

Unit Test: Ensure Game Server Manager has registered available servers in Redis. Trigger matchmaking logic. Verify it calls the allocation API/function. Simulate success: verify players get notified with connection details. Simulate failure (no servers in Redis pool): verify matchmaking logic handles the error gracefully (e.g., logs error, doesn't notify players with bad data).

Troubleshooting: Allocation API errors (check Manager service status, network connectivity). Race conditions leading to double allocation (use atomic Redis operations like SPOP, add locking if needed). Failure handling logic bugs.

STOP & CHECK: Matchmaking service successfully requests and receives game server allocations from the Game Server Manager, handling both success (notifying players) and failure (no servers available) scenarios.

Phase 4: Core Gameplay Loop Integration (w/ Solana)

Goal: Implement the end-to-end flow from frontend matchmaking request to playing the game, concluding the match, and having the result reflected on-chain (escrow release) and off-chain (stats).

4.1 Frontend "Play Game" Flow & Escrow Interaction (Client)

Step 1: Game Selection UI: Create UI components (likely in apps/web) listing available games (initially just "1v1 FPS Duel").

Step 2: Betting UI: Add UI elements for selecting bet amount (predefined tiers: e.g., 1 SOL, 0.5 SOL, 0.1 SOL). Display associated fee (calculate betAmount * 0.05). Show user's SOL balance (useWallet balance might need fetching via connection.getBalance(publicKey)).

Step 3: "Find Match" Action Logic: On clicking "Find Match" for a specific game/bet tier:

Check Balance: Verify client has enough SOL (betAmount + estimated_fees).

Call Escrow Init (Client -> Solana): Construct and send the initialize_escrow transaction (from 2.3) to the Escrow Solana program.

Use @coral-xyz/anchor Provider/Program client initialized with useAnchorWallet() adapter hook and useConnection.

Arguments: game_id, match_id (can be generated client-side for tx, or retrieved after matchmaking starts - simpler to generate placeholder/random for init, real one comes later), bet_amount (in lamports), player_two_pubkey (initially maybe null/placeholder, or matchmaker provides potential opponent first - tricky). Alternative: Matchmaking first, then both players call escrow program. Let's assume Matchmaking First for simpler escrow:

Revised Flow: Click "Find Match" -> Client calls Backend API -> Backend adds to queue. Matchmaker finds pair (P1, P2) -> Matchmaker generates unique matchId -> Backend notifies BOTH P1 and P2 via WebSocket with matchId and opponent pubkey, requesting they initialize/join escrow.

Revised Step 3: On receiving ESCROW_REQUIRED message from backend (with matchId, opponentPubkey, betAmount):

Player 1: Construct and send initialize_escrow transaction (using matchId, betAmount, opponentPubkey). Needs authority key (server's key) passed in accounts.

Player 2: Construct and send join_escrow transaction (using matchId, betAmount). Needs authority key passed in accounts.

Both players need to sign. Use wallet.signTransaction() then potentially connection.sendRawTransaction() or a helper from Anchor.

Step 4: Confirm Escrow Deposit: Client waits for transaction confirmation (connection.confirmTransaction). Handle transaction errors (insufficient funds, program error). Notify backend API upon successful deposit via WebSocket/HTTP.

Step 5: Backend Waits for Both Deposits: Backend/Matchmaker waits for confirmation messages from both players for the same matchId.

Step 6: Request Server Allocation: Once both deposits confirmed, backend calls Game Server Manager to allocate server (from 3.3).

Step 7: Redirect Client: Backend sends MATCH_FOUND (from 4.1.3) with server IP/port to both clients. Client disconnects from matchmaking service and connects to the game instance.

Why: Integrates the on-chain betting requirement directly into the matchmaking flow. Ensures funds are secured in escrow before a game server is assigned and gameplay begins. Requires coordination between clients and backend. Using server authority key allows server to release funds later.

Tip: Solana transaction confirmation can take time. Provide clear UI feedback ("Waiting for your confirmation...", "Waiting for opponent...", "Depositing SOL...", "Connecting to game..."). Handle timeouts gracefully if opponent never deposits. Secure the server authority keypair used by the Escrow program very carefully.

Unit Test: Click "Find Match". Verify backend adds to queue. Simulate match found; verify backend sends ESCROW_REQUIRED to both clients. Simulate Client 1 sending initialize_escrow tx; verify backend notified on success. Simulate Client 2 sending join_escrow tx; verify backend notified. Verify backend then requests server allocation and sends MATCH_FOUND to clients. Verify client connection logic triggers. Test cases where one player fails tx, or times out. Check escrow account state on Solana Explorer at each step.

Troubleshooting: Solana transaction errors (check program logs via Explorer, check account inputs, insufficient funds, signature issues). Backend coordination logic errors (waiting for confirmations, timeouts). Client UI feedback confusing. Escrow account state incorrect.

STOP & CHECK: End-to-end flow from "Find Match" click through backend coordination, client-side Solana transaction signing for escrow deposit, backend confirmation, server allocation, and client redirection to game instance is functional.

4.2 Game Instance / Solana Program Interaction (Server)

Step 1: Provide Authority Keypair: Securely provide the Escrow program's designated authority keypair to the gameInstance.js process (e.g., via secure volume mount in Kubernetes, environment variable with keypair bytes - less secure, or dedicated secrets management). Security is paramount here.

Step 2: Initialize Anchor Client (Game Instance): Inside gameInstance.js, load the authority keypair. Initialize the Anchor Provider and Program client for interacting with the Escrow and Player Profile programs using the server's authority keypair as the signer/wallet.

Step 3: Identify Match Context: On startup, the game instance knows its matchId. When players connect, it verifies their playerId against the expected players for that matchId (potentially fetched from Redis/Manager). It retrieves the corresponding on-chain escrow account PDA address based on the known players and matchId.

Step 4: Determine Winner Logic: After the game logic determines the winner (e.g., handlePlayerDeath leads to endMatch which identifies winnerPlayerId), retrieve the winner's wallet Pubkey.

Step 5: Call ReleaseEscrow (Server -> Solana): Construct and send the release_escrow transaction to the Solana Escrow program using the Anchor client initialized with the server's authority keypair.

Pass the match_escrow PDA, escrow_vault PDA, winner's Pubkey (as winner_account), and system_program.

The server authority signs this transaction.

Wait for transaction confirmation. Log success or failure. Handle retries carefully if needed.

Step 6: Call UpdateStats (Server -> Solana - Optional On-Chain): If storing W/L on-chain:

Construct and send update_stats transaction to the Player Profile program for both players (one with +1 win, one with +1 loss).

This requires the update_stats instruction to be callable by the same server authority keypair (or a different designated key). Add necessary account inputs (player_profile PDA, server_authority signer).

Alternative: Update off-chain stats (in Postgres/Mongo) instead, which is often simpler and cheaper. Only store core verifiable data on-chain if necessary. Recommendation: Update off-chain stats first.

Step 7: Report Full Results: After Solana interactions (or in parallel if stats are off-chain), send the final MATCH_RESULT message (via IPC or API, from 3.2) including winner, loser, scores, and confirmation that escrow was released (or error if failed).

Why: Enables the trusted off-chain game server (which determines the factual outcome) to trigger the on-chain release of escrowed funds and potentially update on-chain player stats, acting as an oracle. Securing the server's authority keypair is the lynchpin of this trust model.

Tip: Separate Solana interaction logic into dedicated modules. Handle potential Solana RPC errors and transaction failures gracefully. Consider gas fees for server transactions. Log all Solana interactions with transaction signatures for auditing.

Unit Test: Simulate a game ending in game instance. Verify it identifies winner. Verify it correctly loads server authority keypair. Verify it constructs and sends release_escrow transaction with correct accounts/winner pubkey, signed by authority. Monitor transaction on Solana Explorer; verify SOL transferred, accounts closed. If using on-chain stats, verify update_stats called and profile accounts updated. Verify MATCH_RESULT sent via IPC/API. Test error cases (e.g., wrong authority key, already released escrow).

Troubleshooting: Authority keypair loading/signing errors. Incorrect PDA addresses derived. release_escrow/update_stats transaction failures (check program logs on Explorer, account inputs, authority mismatch). Insufficient server wallet balance for transaction fees. Security vulnerabilities if keypair exposed.

STOP & CHECK: Game server instance, upon match completion, can use its authority keypair to successfully call the release_escrow Solana program instruction, transferring funds to the winner. Optionally, it can also update on-chain stats. Full results are reported back to the manager/results service.

4.3 Post-Match Flow (Client & Backend)

Step 1: Client Receives Game Over: Game instance sends MATCH_OVER message via Socket.io directly to the two connected players, potentially including winner info and final scores.

Step 2: Client Displays Results: Client UI updates to show "You Win!" / "You Lose!", final scores. Disable game input. Provide button to "Return to Lobby" or "Play Again".

Step 3: Backend Receives Full Result: Game Server Manager receives MATCH_RESULT (via IPC/API) from game instance, including confirmation of escrow release/stats update.

Step 4: Backend Processes Result:

Update off-chain player stats (W/L in Postgres/Mongo User table).

Store detailed match history (from 4.3.2 - if not already done by results service).

Trigger ELO update (from 4.1.1) if using.

Trigger NFT fee distribution (Phase 6 logic).

Step 5: Client Returns to Lobby: When user clicks "Return to Lobby", client disconnects from game instance Socket.io server and potentially reconnects to main platform WebSocket or navigates back to the main Next.js application state (fetching updated profile/balance).

Why: Provides a clean transition from gameplay back to the main platform, ensures results are processed correctly both on-chain and off-chain, and updates the user's view with the outcome and refreshed stats.

Tip: Make the post-match screen informative and quick to navigate away from. Ensure client fetches fresh profile data upon returning to lobby to see updated stats/balance.

Unit Test: Complete a game flow. Verify client receives MATCH_OVER, displays results correctly. Verify backend receives MATCH_RESULT. Check off-chain DB; verify user stats (W/L) updated. Click "Return to Lobby"; verify client disconnects from game server and returns to main app state, potentially fetching and displaying updated profile data.

Troubleshooting: Client doesn't receive MATCH_OVER. Backend doesn't receive/process MATCH_RESULT. Off-chain stats not updating. Client state doesn't refresh correctly after returning.

STOP & CHECK: End-to-end gameplay loop is complete: Players matchmake, deposit escrow, play game, game server releases escrow and reports results, backend processes results updating off-chain state, client displays outcome and returns to platform.

Phase 5: First Game Adaptation (1v1 FPS Example)

Goal: Integrate the specific 1v1 FPS game logic (detailed previously, using Three.js/Rapier/Socket.io) into the managed game server architecture.

5.1 Package FPS Server as Game Instance

Step 1: Adapt FPS Server Script: Take the detailed server-side logic for the 1v1 FPS duel (handling Socket.io connections for 2 players, Rapier world setup with map physics, player input processing with Rapier validation, authoritative state sync, raycast shooting with Rapier, damage model, round flow) and ensure it runs within the gameInstance.js structure defined in Phase 3.

Step 2: Parameterization: Ensure it accepts PORT, matchId, and potentially expected player IDs via process.argv or process.env.

Step 3: Communication Integration: Implement the IPC/API calls (from 3.2) within the FPS logic:

Send READY after server starts listening and registers.

Send MATCH_STARTED when both players connect and countdown ends.

Send MATCH_RESULT (including winner ID, scores) when the FPS match/round logic concludes. Ensure it also includes data needed for Solana interactions (winner pubkey).

Step 4: Solana Integration: Add the logic from 4.2 (loading authority keypair, initializing Anchor client, calling release_escrow, potentially update_stats) triggered by the FPS game's endMatch condition.

Step 5: Configuration: Add specific FPS game config (weapon stats, map data references) potentially loaded based on gameType argument.

Why: Packages the self-contained FPS game logic into the standardized, manageable game instance process required by the platform infrastructure.

Tip: Keep Solana interaction logic modular within the game instance code. Ensure all necessary environment variables or config files are available to the process when spawned.

Unit Test: Spawn the FPS game instance via the Game Server Manager. Verify it sends READY. Simulate two clients connecting; verify MATCH_STARTED sent. Simulate game end; verify MATCH_RESULT sent with correct data AND verify Solana release_escrow transaction is attempted/logged.

Troubleshooting: Game logic errors specific to FPS. IPC messages not sent correctly. Solana interaction logic fails within game context (keypair access, Anchor client).

STOP & CHECK: The 1v1 FPS server logic is successfully packaged as a manageable game instance process, communicating its status and results, and triggering required Solana interactions.

5.2 Client-Side Game Component Integration (Next.js)

Step 1: Create Game View Component: In apps/web, create a React component (e.g., components/GameViewFPS.tsx) responsible for rendering the Three.js canvas and handling game-specific client logic for the FPS game.

Step 2: Initialize Three/Rapier: Within GameViewFPS.tsx, use useEffect hook to initialize the Three.js renderer, scene, camera, load map visuals, initialize the client-side Rapier world with map physics, set up the render loop (as detailed in FPS plan Phase 1-2). Ensure cleanup logic in useEffect return function.

Step 3: Socket.io Connection (Game Instance): When this component mounts (triggered after receiving MATCH_FOUND and navigating):

Establish a new Socket.io connection to the specific game server IP/port received.

Set up listeners for game-specific messages (GAME_STATE, PLAYER_DIED, HIT_CONFIRMED, etc.).

Handle disconnection from game server (e.g., on match end message or error).

Step 4: Input Handling: Attach keyboard/mouse listeners within this component, feeding input into the client-side prediction (Rapier) and network sending logic specific to the FPS game. Ensure pointer lock is requested for the canvas container.

Step 5: Rendering Logic: The component's render loop updates Three.js visuals based on the client's Rapier world state (predicted local player, interpolated remote player), handles FPV/Third-person views, plays animations.

Step 6: Conditional Rendering: Render this GameViewFPS component dynamically within the Next.js app only when the user is actively in an FPS match state.

Why: Encapsulates the client-side logic and rendering for a specific game within a reusable React component, integrated into the overall Next.js application flow. Separates concerns between platform UI and in-game rendering/interaction.

Tip: Pass necessary connection info (IP/port, matchId) as props to the GameViewFPS component. Manage component mounting/unmounting carefully to ensure proper setup/cleanup of Three.js, Rapier, and Socket.io resources.

Unit Test: Navigate to the game view state in the app. Verify the GameViewFPS component mounts. Verify it connects to the correct game server Socket.io endpoint. Verify Three.js canvas renders, Rapier initializes. Test input handling within the component. Verify disconnection logic works when component unmounts or receives game over signal.

Troubleshooting: Three.js/Rapier initialization errors within React context. Socket.io connection issues to game server. Input listeners conflicting or not capturing correctly. Resource leaks if cleanup logic is missing. State management between Next.js app state and game component state.

STOP & CHECK: The client-side FPS game logic and rendering are encapsulated within a React component, successfully connects to the dedicated game server instance, and handles input and rendering for the duration of the match.

5.3 Game Asset Handling

Step 1: Place Assets: Store game-specific assets (GLB models for characters/weapons/maps, textures, sound files) in the apps/web/public directory, organized by game (e.g., public/assets/fps_1v1/models/).

Step 2: Loading Logic: Use standard Three.js loaders (GLTFLoader, TextureLoader, AudioLoader) within the client-side game component (GameViewFPS.tsx) to load assets using relative paths from the /public root (e.g., /assets/fps_1v1/models/player.glb).

Step 3: Preloading Strategy (Optional): For better user experience, implement a preloading phase before the game view component fully mounts or before the match countdown finishes. Load critical assets needed immediately first. Show loading progress indicator.

Why: Ensures the client can access and load the visual and audio resources needed for the specific game being played. Using the public directory makes them directly servable by the Next.js web server.

Tip: Optimize asset sizes (compress textures, simplify models). Consider using a CDN for assets in production to improve load times globally.

Unit Test: Verify game component successfully loads required models, textures, and sounds using correct paths. Check browser network tab to confirm assets are fetched. Test preloading logic and progress display if implemented.

Troubleshooting: 404 errors for assets (check paths in code vs actual file locations in public). Slow loading times (optimize assets, implement preloading, consider CDN). CORS issues if assets hosted elsewhere.

STOP & CHECK: Game-specific assets (models, textures, sounds) are correctly placed, loaded, and utilized by the client-side game component.

Phase 6: NFT System Foundation (V1 - Planning & Metadata)

Goal: Define the structure, metadata, and initial linking mechanism for Player NFTs, preparing for minting and marketplace features later.

6.1 NFT Metadata Standard (Metaplex Token Metadata)

Step 1: Choose Standard: Adopt the Metaplex Token Metadata standard for on-chain metadata associated with the Player NFTs. This is the Solana ecosystem standard, ensuring compatibility with wallets and marketplaces.

Step 2: Define Metadata Fields: Plan the JSON structure for the off-chain metadata file (URI stored on the NFT):

{
  "name": "PlayerName - Player NFT #Serial/6", // Dynamic Name
  "symbol": "PLAYER", // Or a specific game symbol
  "description": "NFT representing ownership stake in PlayerName's match fee earnings.",
  "seller_fee_basis_points": 500, // Example: 5% royalty on secondary sales
  "image": "URI_to_dynamic_NFT_image", // See Step 3
  "external_url": "URL_to_player_profile_on_platform",
  "attributes": [
    { "trait_type": "Player Name", "value": "PlayerName" },
    { "trait_type": "Player Wallet", "value": "PlayerWalletAddress" },
    { "trait_type": "Serial Number", "value": "Serial/6" }, // 1 to 6
    { "trait_type": "Overall Win Rate", "value": "65%" }, // Dynamic
    { "trait_type": "Total Fees Earned (Lifetime)", "value": "125.5 SOL" }, // Dynamic sum for this NFT
    // Add more dynamic stats if desired
  ],
  "properties": {
    "files": [ { "uri": "URI_to_dynamic_NFT_image", "type": "image/png" } ], // Or SVG
    "category": "image" // Or could be json if metadata includes dynamic parts directly
  }
}


Step 3: Dynamic Image/Metadata Strategy: Plan how the image URI and dynamic attributes (Win Rate, Fees Earned) will be updated. Options:

Off-Chain Metadata Server: Mint NFT pointing to a metadata URI hosted by your API (/api/nft/metadata/{mintAddress}). This API dynamically generates the JSON metadata (fetching latest player stats) and potentially generates a dynamic SVG/Canvas image on the fly, or serves a pre-rendered image updated periodically. Recommended for flexibility.

On-Chain Metadata (Limited): Some simple dynamic traits could potentially be stored directly in the Token Metadata account if space allows and updated via program calls, but complex strings/images are not feasible. Not recommended for this use case.

Why: Using the Metaplex standard ensures compatibility. Defining the metadata structure clarifies what information the NFT represents. Planning for dynamic updates is crucial for reflecting player performance and fee earnings on the NFT itself. An off-chain metadata server provides the most flexibility.

Tip: Keep dynamic attribute updates efficient. Cache generated metadata/images. Ensure the metadata server is reliable and scalable.

Unit Test: Create sample JSON metadata files following the defined structure. Validate them against Metaplex standards/tools if possible. Design the API endpoint logic (/api/nft/metadata/{mintAddress}) to fetch relevant player/NFT data and return the correct JSON structure. Test accessing the endpoint. Plan the dynamic image generation strategy.

Troubleshooting: Metadata format errors. API endpoint logic bugs. Dynamic data fetching issues. Performance of dynamic image generation.

STOP & CHECK: Metaplex Token Metadata standard adopted. Metadata JSON structure defined, including dynamic attributes. Strategy for serving dynamic metadata/images via an off-chain API endpoint is chosen.

6.2 Player-NFT Linking and Initial Distribution

Step 1: Define the Relationship: 1 Player <-> 6 unique NFTs. The player automatically owns NFTs #1, #2, #3. NFTs #4, #5, #6 are initially held by the platform/treasury for sale on the marketplace.

Step 2: Representing the Link: How to associate the 6 NFT mint addresses with the player?

Off-Chain Database: Add an array playerNftMints: [String] to the off-chain User profile (Postgres/Mongo). Store the 6 mint addresses here after they are created. Simplest and recommended.

On-Chain (Advanced): Create another PDA account per player PlayerNftRegistry seeded by player authority, storing the 6 mint addresses. More complex, consumes rent, but fully on-chain.

Step 3: Initial "Minting" / Allocation Plan (Conceptual - Actual minting later):

When a player creates their on-chain profile (via create_profile instruction), trigger an off-chain process (e.g., via backend listening to profile creation or an explicit API call).

This backend process will (in a later phase):

Generate 6 new SPL Token mints (NFTs using Metaplex standard).

Create the associated metadata accounts pointing to the dynamic metadata API endpoint (/api/nft/metadata/{mintAddress}), embedding the player's ID/wallet and serial number (1-6) within the context for the API.

Create token accounts for each mint.

Transfer NFTs #1, #2, #3 to the player's wallet.

Transfer NFTs #4, #5, #6 to a platform treasury wallet.

Update the off-chain User.playerNftMints array (or on-chain registry) with the 6 mint addresses.

Why: Defines the fixed supply and initial distribution mechanism for each player's NFTs. Establishes how the system knows which NFTs belong to which player, essential for fee distribution and marketplace functionality. Off-chain mapping is simpler to start.

Tip: Automate the minting/distribution process reliably. Handle potential failures during minting. Secure the treasury wallet holding NFTs #4-6.

Unit Test: (Conceptual for now) Design the database schema change for User.playerNftMints. Design the off-chain backend function signature createAndDistributePlayerNfts(playerId, playerWalletAddress). Outline the steps it needs to perform (minting, metadata creation, transfers, DB update).

Troubleshooting: (Anticipated) Minting failures (insufficient SOL for rent/fees). Metadata creation errors. Token transfer failures. Database update failures. Ensuring atomicity of the whole process.

STOP & CHECK: The 1-player-to-6-NFTs relationship is defined. Method for linking mint addresses to players (off-chain DB recommended) is chosen. Conceptual plan for the off-chain minting and initial distribution process exists.

6.3 NFT Marketplace Foundation (Backend/UI Placeholders)

Step 1: Define Core Marketplace Features (V1):

View Player NFTs (#4, #5, #6) listed for sale by the platform/treasury.

Allow users to buy these platform-listed NFTs for a set SOL price.

(Later V2: Allow users to list their owned NFTs (#1-6) for sale, peer-to-peer).

Step 2: Backend API Structure (Placeholders): Define necessary API endpoints in the Next.js backend (or separate service):

GET /api/marketplace/listings?playerId={...}&available=true: Fetch NFTs currently listed for sale (initially just #4-6 from treasury for a given player). Needs logic to check treasury wallet ownership.

POST /api/marketplace/buy: Handle purchase attempts. Needs parameters like nftMintAddress, buyer wallet address. Server-side logic would eventually construct the necessary Solana transaction(s) for transferring SOL from buyer to treasury and NFT from treasury to buyer (requires treasury wallet authority).

Step 3: Database Schema (Optional): May need tables/collections for MarketplaceListings if implementing P2P sales later. For V1 (platform sales), might just query treasury wallet contents directly or have a simpler tracking mechanism.

Step 4: Client UI Placeholders: Create basic UI pages/components in apps/web:

Player Profile Page: Add section "NFTs for Sale" - initially fetches/displays data from GET /api/marketplace/listings. Add "Buy" button (non-functional initially).

Marketplace Page (Optional): A central page listing all available platform-held NFTs (#4-6 across all players).

Why: Sets up the basic API and UI structure for the NFT marketplace, focusing initially on the platform selling the designated NFTs. Prepares for implementing the actual buy/list logic later.

Tip: Focus on the platform selling first; P2P marketplace adds significant complexity (escrow for listings, offer handling). Ensure API security.

Unit Test: Create placeholder API endpoints that return mock listing data. Verify client UI fetches and displays this mock data correctly on profile/marketplace pages. Verify "Buy" button exists (no action yet). Design the expected request/response structure for the buy endpoint.

Troubleshooting: API routing/logic errors. Client fetching/display bugs. Planning for secure transaction construction on the backend for the buy action.

STOP & CHECK: Basic API endpoint structure and client UI placeholders for viewing platform-listed Player NFTs (#4-6) are created, preparing for future implementation of buy/list functionality.

This concludes Part 2. Key achievements:

Off-chain game server management architecture designed using Node.js and Redis.

End-to-end gameplay loop integrated, including Solana escrow deposit by players and release by the authorized game server.

Plan for adapting the 1v1 FPS game into the managed instance structure.

Foundational planning for Player NFTs completed (metadata standard, linking mechanism, initial distribution concept, basic marketplace placeholders).

Part 3 would logically focus on:

Implementing the NFT Minting & Distribution: Writing the off-chain backend service to actually create the NFTs, set metadata, and distribute them.

Implementing the NFT Marketplace (Buy Functionality): Building the backend logic and Solana transaction construction for users to buy the platform-listed NFTs (#4-6).

Implementing Fee Distribution: Designing and implementing the mechanism to calculate and distribute match fees to NFT holders after a match concludes (likely involving off-chain calculation and Solana transfers or a dedicated Solana program).

Social Features: Implementing the backend and frontend for Private Messaging and the Player Feed.

Leaderboards & Profiles (Refinement): Building the UI and API endpoints for the detailed leaderboards (per-game, overall) and enhancing profile display.






Okay, let's dive into Part 3 of the detailed plan for the Solana Gaming Platform. This part focuses on bringing the NFT system to life (minting, marketplace buy, fee distribution) and adding the core social features.

Part 3: NFT Implementation, Fee Distribution & Social Features

Objective: Implement the actual creation and distribution of Player NFTs, enable users to buy platform-listed NFTs, implement the match fee distribution mechanism to NFT holders, and build the core social features (messaging, feed).

Phase 7: NFT Minting & Marketplace Implementation (V1)

Goal: Create the Player NFTs on-chain, distribute them according to the plan, and allow users to buy the platform-held NFTs (#4-6).

7.1 NFT Minting & Distribution Service (Backend)

Step 1: Create Service/Module: Set up a new backend service/module (packages/nft-minter or within main API) responsible for handling NFT creation. Install dependencies: @solana/web3.js, @metaplex-foundation/js, @coral-xyz/anchor.

Step 2: Secure Platform Authority Keypairs: This service needs access to:

Mint Authority Keypair: A keypair authorized to mint new SPL tokens (the NFTs).

Metadata/Update Authority Keypair: A keypair authorized to create/update Metaplex metadata accounts. Often the same as mint authority.

Platform Treasury Keypair: The keypair holding the platform's SOL (for paying minting fees/rent) and receiving NFTs #4-6 initially. Secure these keypairs (Hardware wallet, KMS, dedicated secrets management - NOT hardcoded).

Step 3: Implement createAndDistributePlayerNfts Function: This function (triggered potentially by an internal API call after on-chain profile creation, or a manual admin process initially) takes playerId, playerWalletAddress, playerName. Inside:

Loop 6 times (for serial #1-6):

Generate Mint Keypair: const mintKp = Keypair.generate();.

Use Metaplex SDK (@metaplex-foundation/js): This SDK simplifies Metaplex interactions significantly. Initialize Metaplex using a connection and the platform authority keypair(s).

Create NFT: Use metaplex.nfts().create({ useNewMint: mintKp, payer: platformTreasuryKp, mintAuthority: mintAuthorityKp, updateAuthority: metadataAuthorityKp, name: \
{serial}/6`, symbol: "PLAYER", uri: `https://yourplatform.com/api/nft/metadata/${mintKp.publicKey.toBase58()}\`, // Dynamic metadata URI sellerFeeBasisPoints: 500, isMutable: true, // Allow metadata updates if needed later tokenStandard: 'NonFungible', // Or ProgrammableNFT if using rulesets ... other Metaplex config ... });`. This handles mint creation, token account creation, metadata account creation, and minting 1 token to the specified owner (initially treasury or player).

Let nftOutput = await metaplex.nfts().create(...). nftOutput.mintAddress is the address of the created NFT. Store this mintAddress.

Transfer Ownership (NFTs #1-3): If serial <= 3, use metaplex.nfts().transfer({ nftOrSft: { address: mintAddress, tokenStandard: 'NonFungible' }, fromOwner: platformTreasuryKp.publicKey, toOwner: playerWalletAddress, authority: platformTreasuryKp, payer: platformTreasuryKp }); to transfer the newly minted NFT from the default owner (payer/treasury) to the player. (Alternatively, the create call might allow specifying initial owner).

NFTs #4-6 remain owned by the platformTreasuryKp (or whoever paid for the create call initially).

After Loop: Collect all 6 mintAddress values.

Update Off-Chain DB: Update the User record for playerId in Postgres/Mongo, setting the playerNftMints array field with the 6 mint addresses.

Step 4: Triggering Mechanism: Decide how this function is called reliably after player profile creation. Options: listen to Solana program logs for ProfileCreated event (complex), have the client call a "claim NFTs" API after profile creation, manual admin trigger. Recommendation: Start with an internal API endpoint triggered after successful off-chain user registration linked to on-chain profile check.

Why: Automates the creation of the 6 unique NFTs per player according to the Metaplex standard, assigns initial ownership (3 to player, 3 to platform), and links the mint addresses back to the off-chain player record for future reference. Using the Metaplex SDK abstracts away much of the low-level Solana instruction complexity.

Tip: Minting costs SOL (rent for mint, token, metadata accounts + tx fees). Ensure the treasury wallet is funded. Handle errors robustly (e.g., if one mint fails, should it retry? Rollback?). Perform minting asynchronously outside the user request flow if possible.

Unit Test: Set up mock Metaplex SDK calls or test against Devnet. Trigger the function for a test player. Verify 6 distinct NFTs are created (check Solana Explorer). Verify metadata URIs point to the correct API endpoint format. Verify NFTs #1-3 appear in the player's Devnet wallet and #4-6 in the treasury wallet. Verify the playerNftMints array in the off-chain DB is populated correctly with the 6 mint addresses.

Troubleshooting: Metaplex SDK errors (check authentication, parameters, connection). Insufficient funds in treasury wallet. Solana transaction failures during mint/transfer. DB update failures. Idempotency issues if triggered multiple times.

STOP & CHECK: Backend service can successfully mint 6 Metaplex NFTs per player, distribute ownership correctly (3 to player, 3 to treasury), and link the mint addresses to the player's off-chain profile.

7.2 Dynamic Metadata/Image Server (API Endpoint)

Step 1: Create API Route: In apps/web (or separate service), implement the API route defined earlier: pages/api/nft/metadata/[mintAddress].ts.

Step 2: Fetch Data: Inside the API route handler:

Get mintAddress from the URL parameter.

Look up which player this mintAddress belongs to (query the off-chain User DB where playerNftMints array contains mintAddress). Find the associated playerId, playerName, playerWalletAddress. Determine the serial number (1-6) based on its index in the array.

Fetch the player's latest stats (Overall Win Rate, potentially others) from the Player Profile Solana account (using connection.getAccountInfo and Anchor Borsh deserialization) or the off-chain stats DB.

Fetch the total fees earned specifically by this NFT serial number for this player (requires fee distribution tracking - see Phase 8). For V1, this might be 0 or placeholder.

Step 3: Generate JSON Metadata: Construct the JSON object according to the Metaplex standard defined in 6.1, dynamically filling in name, external_url, and attributes (Player Name, Wallet, Serial, Win Rate, Fees Earned) based on the fetched data.

Step 4: Generate/Serve Image URI: Determine the image URI field:

Option A (Dynamic SVG/Canvas): Generate an SVG image string or render to a canvas buffer on the fly within the API route, embedding the dynamic stats directly into the image. Return the image data directly with appropriate content type, or return a data URI.

Option B (Static Template + Dynamic Query Params): Have a static base image template (e.g., background, frame). The image URI points to another API endpoint /api/nft/image/{mintAddress}. This second endpoint generates the image (maybe overlaying text on the template) based on fetched stats.

Option C (Pre-rendered, Periodically Updated): Have a background job periodically render images for all NFTs based on current stats and upload them to IPFS/Arweave/S3. The metadata API just returns the latest stored image URI. Recommended for performance if image generation is slow.

Step 5: Return JSON Response: Send the complete JSON metadata object as the API response with Content-Type: application/json. Implement caching (e.g., using Cache-Control headers) to reduce load.

Why: Provides the dynamic, off-chain data source required by the Metaplex standard. Allows NFT marketplaces and wallets to display up-to-date information (stats, earnings) associated with the player NFT by simply fetching the metadata URI stored on the NFT.

Tip: Optimize data fetching within the API route. Cache heavily, especially player stats and generated images. Ensure the API is scalable and reliable. Validate mintAddress input.

Unit Test: Call the API endpoint /api/nft/metadata/{nftMintAddress} (using a mint address created in 7.1). Verify the returned JSON matches the Metaplex structure. Verify dynamic fields (name, attributes) contain correct data fetched from DB/on-chain profile/fee tracking. Verify the image URI is correct based on the chosen strategy. Test with different mint addresses/serial numbers. Check response headers for caching.

Troubleshooting: API errors (data fetching fails, DB query errors, Solana connection issues). JSON format errors. Dynamic image generation errors/performance issues. Caching misconfigurations. Player lookup based on mint address fails.

STOP & CHECK: A dynamic metadata API endpoint exists that, given an NFT mint address, can look up the associated player, fetch their current stats/earnings, and return valid Metaplex JSON metadata including dynamic attributes and a working image URI.

7.3 Marketplace "Buy Platform NFT" Logic (V1)

Step 1: API Endpoint (GET /api/marketplace/listings): Implement the backend logic:

Accept optional playerId filter.

Identify platform treasury wallet address.

Use Solana connection.getTokensByOwner(treasuryPubkey) (or Metaplex SDK equivalent metaplex.nfts().findAllByOwner({ owner: treasuryPubkey })) to find all NFTs owned by the treasury.

Filter these NFTs to find those matching the Player NFT structure (e.g., based on collection address if used, or naming convention, or symbol). Further filter by playerId if provided. Keep only serials #4-6.

For each found NFT, fetch its metadata (using internal call to metadata API or directly if feasible) to get details like name, image, player association.

Define the fixed price (in SOL) for platform NFTs.

Return a list of available listings: { mintAddress, name, image, priceSOL, associatedPlayerId, serialNumber }. Implement pagination.

Step 2: Client UI (Marketplace/Profile): Implement the frontend JS logic to:

Call fetch('/api/marketplace/listings?playerId=...').

Display the returned listings with image, name, price, "Buy" button.

Step 3: API Endpoint (POST /api/marketplace/buy): Implement the backend logic:

Receive { nftMintAddress, buyerWalletAddress }. Validate inputs.

Verify nftMintAddress is indeed a platform-held (#4-6) NFT currently listed for sale (check treasury ownership again).

Define the priceLamports.

Construct Solana Transaction (Server-Side): Use @solana/web3.js (or Anchor/Metaplex SDK helpers) to build a transaction with two instructions:

SOL Transfer: SystemProgram.transfer({ fromPubkey: buyerPubkey, toPubkey: platformTreasuryPubkey, lamports: priceLamports }).

NFT Transfer: Instruction to transfer the NFT from the treasury's token account to the buyer's associated token account (ATA). Use Metaplex SDK metaplex.nfts().transfer(...) or splToken.createTransferInstruction(...). This requires the treasury wallet to sign.

Serialize and Return: Serialize the unsigned transaction: const serializedTx = transaction.serialize({ requireAllSignatures: false });. Return Buffer.from(serializedTx).toString('base64') to the client. The server only prepares the transaction; the buyer signs the SOL transfer part, the treasury signs the NFT transfer part.

Step 4: Client-Side Signing & Sending: On clicking "Buy":

Client calls POST /api/marketplace/buy.

Receives the base64 serialized transaction from the API response.

Deserialize: const transaction = Transaction.from(Buffer.from(base64Tx, 'base64'));.

Sign using the connected wallet: const signedTx = await wallet.signTransaction(transaction);. (The buyer only needs to sign the instruction involving their SOL transfer).

Send the partially signed transaction: const signature = await connection.sendRawTransaction(signedTx.serialize());.

Confirm transaction: await connection.confirmTransaction(signature);.

Provide UI feedback (success/failure).

Step 5: Treasury Signing (Implicit or Server-Side): The NFT transfer instruction needs the Treasury's signature. This was likely added when the server constructed the transaction using the Metaplex SDK helpers if the SDK was initialized with the treasury keypair. Verify the SDK handles signing with the provided authority correctly. If manual construction used, ensure treasury signs its part before serializing and sending to client. The key is the server constructs the TX, includes the required treasury signature for the NFT transfer, and the client adds their signature for the SOL transfer.

Why: Implements the core logic for selling the platform-held NFTs. The backend verifies availability and constructs the atomic transaction involving both SOL payment and NFT transfer. The client signs only the part they authorize (payment), and the server (via treasury keypair) authorizes the NFT transfer.

Tip: Use Metaplex JS SDK for constructing the buy transaction as it handles Associated Token Account creation/finding and requires less manual instruction building. Ensure the server never exposes the treasury private key. All signing with treasury key happens server-side before sending the transaction to the buyer for their signature. Error handling and transaction confirmation on the client are crucial.

Unit Test: List platform NFTs via API; verify correct NFTs (#4-6) shown. Click "Buy" on client. Verify API call made. Verify backend returns serialized transaction. Verify client wallet prompts for signing. Sign transaction. Verify transaction succeeds on Solana Explorer (check SOL transferred from buyer to treasury, NFT transferred from treasury to buyer). Verify NFT disappears from marketplace listings. Test insufficient SOL balance case. Test buying already sold NFT.

Troubleshooting: Incorrect transaction construction (missing signatures, wrong accounts, incorrect instructions). Client signing errors. Solana transaction failures (check compute units, account states, program logs). Race conditions if multiple users try to buy the same NFT. Server-side treasury signing issues.

STOP & CHECK: Users can view platform-listed NFTs (#4-6) for sale, the backend constructs the correct atomic buy transaction (SOL payment + NFT transfer), the client signs the payment part, and upon successful execution, the buyer receives the NFT and the platform receives the SOL.

Phase 8: Fee Distribution Mechanism

Goal: Implement the system to collect match fees and distribute them to the NFT holders of the winning player.

8.1 Fee Collection (Integrated with Escrow)

Step 1: Define Fee Percentage: Set the fee globally const MATCH_FEE_PERCENT = 0.05; // 5%.

Step 2: Modify Escrow Logic: Adjust the initialize_escrow and join_escrow instructions OR the client-side deposit logic:

Option A (On-Chain Fee Split - More Complex): The release_escrow instruction becomes more complex. Instead of sending 2 * betAmount to winner, it calculates fee = 2 * betAmount * MATCH_FEE_PERCENT. It sends (2 * betAmount) - fee to the winner. The fee amount remains in the vault (or transferred to a separate fee vault PDA). This fee vault then needs another mechanism (separate instruction or off-chain) to distribute to NFT holders. Adds significant on-chain complexity and cost.

Option B (Off-Chain Fee Handling - Recommended): Escrow program remains simple (releases full 2 * betAmount to winner). The fee logic is handled off-chain. The platform relies on players knowing a fee exists. Simplest to implement.

Option C (Fee Added to Deposit): Client calculates totalDeposit = betAmount + (betAmount * MATCH_FEE_PERCENT). Escrow instructions (initialize_escrow, join_escrow) accept totalDeposit. The release_escrow instruction sends betAmount * 2 to the winner, and (betAmount * MATCH_FEE_PERCENT) * 2 to a designated platform fee wallet address (passed into release_escrow accounts). This is a reasonable compromise.

Step 3: Implement Chosen Method: Let's assume Option C (Fee Added to Deposit).

Update client UI to show totalDeposit = betAmount + fee. Check balance against this total.

Modify initialize_escrow and join_escrow instructions to accept/expect totalDeposit amount transferred into the vault. Update internal bet_amount state perhaps just for tracking base bet.

Modify ReleaseEscrow context to include platform_fee_wallet: AccountInfo<'info> (mut).

Modify release_escrow logic: Calculate winnerAmount = betAmount * 2 and totalFee = totalDeposit * 2 - winnerAmount. Transfer winnerAmount to winner_account, transfer totalFee to platform_fee_wallet. Close escrow/vault.

Why: Ensures the match fee is collected reliably as part of the betting process. Option C keeps the fee collection atomic with the escrow and makes funds immediately available in a known platform wallet for off-chain distribution.

Tip: Clearly communicate the fee structure to users in the UI. Ensure fee calculation logic is accurate (handle potential floating point issues carefully, work in lamports).

Unit Test: (Option C) Update JS tests for escrow: Verify client calculates totalDeposit correctly. Verify initialize_escrow and join_escrow expect and receive totalDeposit. Verify release_escrow correctly splits funds: betAmount * 2 to winner, totalFee to platform fee wallet. Check wallet balances after release using Explorer/RPC calls.

Troubleshooting: Incorrect fee calculation. Insufficient deposit amount if client calculates wrong. release_escrow transfer logic errors (wrong amounts, wrong recipient accounts). Platform fee wallet not receiving funds.

STOP & CHECK: Match fee collection is integrated into the escrow process (e.g., added to deposit), and the release_escrow instruction correctly separates the base bet winnings from the collected fees, sending fees to a designated platform wallet.

8.2 Off-Chain Fee Calculation & Distribution Logic (Backend)

Step 1: Create Fee Processing Service/Module: Set up a backend service/module (packages/fee-distributor or within main API) responsible for distributing collected fees. Needs access to player profiles (for NFT mint list) and potentially a queue of processed matches. Needs access to a Platform Distribution Wallet Keypair (separate from treasury/authority, funded with SOL for transaction fees, potentially funded by fees collected).

Step 2: Trigger Distribution: After a match result is processed by the backend (from 4.3 or results service) and escrow release confirmed:

Get the winnerPlayerId and the totalFee collected for that match (can be calculated from betAmount or retrieved from match data).

Step 3: Identify NFT Holders:

Fetch the winner's playerNftMints array (6 mint addresses) from the off-chain User DB.

For each of the 6 mintAddress values: Use Solana connection.getTokenLargestAccounts(mintAddress) or Metaplex SDK metaplex.nfts().findByMint({ mintAddress }) and inspect ownership details to find the current owner's wallet address for that specific NFT serial number. (Handles cases where NFTs #1-6 might have been sold/transferred).

Step 4: Calculate Per-NFT Share: perNftShareLamports = Math.floor(totalFeeLamports / 6);. (Handle potential rounding remainders - maybe accumulate in platform wallet).

Step 5: Construct Distribution Transactions (Backend): For each NFT holder identified:

Create a simple SOL transfer instruction: SystemProgram.transfer({ fromPubkey: platformDistributionPubkey, toPubkey: nftHolderWalletAddress, lamports: perNftShareLamports }).

Batching: Group multiple transfers (e.g., up to 10-15 small transfers) into a single Solana transaction to save on transaction fees. Add a memo instruction identifying the match/purpose for traceability.

Step 6: Sign and Send (Backend): Sign the batched transaction(s) using the Platform Distribution Wallet Keypair. Send using connection.sendRawTransaction. Wait for confirmation. Log success/failure for each distribution. Handle retries if necessary.

Step 7: Track Fees Earned (Per NFT): Store the distributed amount (perNftShareLamports) associated with the specific mintAddress and matchId in a new database table/collection (e.g., nft_earnings) for querying by the dynamic metadata API (7.2). Structure: { earningId, mintAddress, matchId, timestamp, amountLamports, recipientWallet }.

Why: Implements the core NFT utility: rewarding holders based on the player's success. Off-chain calculation and distribution using a dedicated wallet is more flexible and potentially cheaper (batching transactions) than complex on-chain distribution programs. Tracking earnings allows dynamic metadata updates.

Tip: Secure the distribution wallet keypair. Implement robust error handling and logging for distribution transfers. Handle cases where NFT ownership might be a program/contract address (e.g., listed on marketplace). Start distribution logic asynchronously after match completion. Batching is crucial for cost savings.

Unit Test: Simulate a match end with a known winner and fee amount. Trigger distribution logic. Verify it correctly fetches winner's 6 NFT mints. Simulate fetching current owners for those mints (use test wallets). Verify it calculates perNftShare. Verify it constructs batched SOL transfer transactions signed by distribution wallet. Send transaction to Devnet. Verify test NFT holder wallets receive the correct SOL amount (check balances). Verify earnings are recorded in nft_earnings DB table. Test edge cases (NFTs still held by treasury, fractional lamport remainders).

Troubleshooting: Incorrect NFT holder lookup. Incorrect share calculation. Solana transfer failures (insufficient funds in distribution wallet, invalid recipient address). Transaction batching errors. DB logging failures for earnings. Performance issues if fetching many NFT owners.

STOP & CHECK: Backend service reliably identifies NFT holders for the winning player after a match, calculates fee shares, constructs and sends batched SOL transfer transactions to distribute fees, and logs earnings per NFT.

8.3 Update Dynamic NFT Metadata (Trigger)

Step 1: Identify Trigger Point: When should the dynamic Total Fees Earned attribute (and potentially Win Rate) on the NFT metadata be updated?

Option A (On Distribution): After successful fee distribution (Step 6 in 8.2), trigger an update for the relevant metadata cache.

Option B (Periodic Cache Refresh): Have a background job periodically query the nft_earnings table, recalculate totals per NFT, and update a cache used by the metadata API.

Option C (On Metadata Request): Calculate the total fees earned live within the metadata API endpoint (7.2) by querying the nft_earnings table every time metadata is requested. Simplest logic, but potentially slow if earnings history grows large.

Step 2: Implement Update/Calculation: Based on chosen trigger:

(Option A/B) Store the calculated total fees earned per mintAddress in a simple Redis cache or update a field in the main User or a dedicated NftStats table.

(Option C) Add DB query logic to the metadata API: const earningsRecords = await db.collection('nft_earnings').find({ mintAddress }).toArray(); const totalEarned = earningsRecords.reduce((sum, record) => sum + record.amountLamports, 0);. Fetch win rate from profile.

Step 3: Metadata API Uses Updated Data: Ensure the metadata API (7.2) reads the cached total (Option A/B) or calculates it live (Option C) and includes it in the attributes section of the returned JSON.

Why: Ensures the NFT metadata displayed by wallets/marketplaces reflects the accumulated earnings, fulfilling the dynamic aspect of the NFT's utility.

Tip: For performance and scalability, avoid calculating totals live on every metadata request (Option C) if earnings history can become large. Use caching (Option A/B).

Unit Test: Distribute fees for an NFT (test from 8.2). Trigger the chosen update mechanism. Call the metadata API endpoint for that NFT's mintAddress. Verify the Total Fees Earned attribute in the returned JSON reflects the newly added amount. Update player win rate; verify that attribute also updates on next metadata fetch.

Troubleshooting: Cache not updating/invalidating correctly. Live calculation query slow. Data mismatch between earnings table and metadata attribute.

STOP & CHECK: Mechanism is in place to update the dynamic 'Total Fees Earned' (and other stats like Win Rate) displayed in the NFT metadata, triggered either by distribution events or periodic refresh/live calculation.

Phase 9: Social Features

Goal: Implement basic social interaction features: private messaging and a public feed.

9.1 Private Messaging (Backend & Socket.io)

Step 1: Choose Technology:

Option A (WebSocket Based): Use the main platform's Socket.io connection (or a dedicated chat connection) for real-time message delivery. Requires managing user online status and message routing.

Option B (API Polling/Push): Use backend API endpoints to send/receive messages, potentially with polling or server-sent events for notifications. Simpler backend state but less real-time feel.

Recommendation: Leverage existing main platform Socket.io connection if possible for real-time feel.

Step 2: Database Schema (Off-Chain): Create tables/collections in Postgres/Mongo:

Conversations: id, participant1Id (FK to User), participant2Id (FK to User), lastMessageTimestamp, createdAt. Unique constraint on (participant1Id, participant2Id).

Messages: id, conversationId (FK), senderId (FK to User), contentText, timestamp, isRead.

Step 3: Backend Logic (Socket.io Server):

Maintain mapping: userId -> socketId (when user connects to main platform socket).

SEND_PRIVATE_MESSAGE Event Handler: Receives { recipientUserId, contentText }.

Find or create Conversation between senderUserId (from socket) and recipientUserId.

Create new Message record in DB linked to conversation, sender, content, timestamp. Mark isRead = false.

Find recipient's socketId from mapping.

If recipient online: io.to(recipientSocketId).emit(MessageType.RECEIVE_PRIVATE_MESSAGE, { senderId, contentText, timestamp, conversationId });. Also emit back to sender for confirmation/UI update.

Update lastMessageTimestamp on Conversation.

Step 4: Fetching Logic (API Endpoints): Create backend API endpoints:

GET /api/chat/conversations: Fetch list of conversations for logged-in user, ordered by lastMessageTimestamp, potentially with last message snippet and unread count.

GET /api/chat/conversations/{conversationId}/messages: Fetch messages for a specific conversation (paginate). Mark messages as isRead = true upon fetching.

Step 5: Client UI (React Components):

Chat List Component: Calls /api/chat/conversations, displays list, indicates unread messages. Listens for RECEIVE_PRIVATE_MESSAGE socket event to update list/unread counts in real-time.

Conversation View Component: Takes conversationId. Calls /api/chat/conversations/.../messages to load history. Displays messages. Includes input field to send new messages (emits SEND_PRIVATE_MESSAGE socket event). Listens for RECEIVE_PRIVATE_MESSAGE socket event to append new incoming messages for the current conversation in real-time.

Why: Provides a standard private communication channel between users on the platform, enhancing community interaction. Using Socket.io makes it real-time. Storing persistently allows message history.

Tip: Implement robust authentication/authorization on API endpoints and socket event handlers (user can only access their own conversations/messages). Add rate limiting to sending messages. Consider online status indicators. Paginate message history loading.

Unit Test: Simulate User A sending message to User B (via socket emit). Verify backend creates Conversation/Message DB records. If B is online, verify B's client receives RECEIVE_PRIVATE_MESSAGE socket event. Call API to fetch conversations for A and B; verify conversation listed. Call API to fetch messages for the conversation; verify message appears and isRead status updates. Test sending message when recipient offline (should still save to DB, recipient sees on next login/fetch).

Troubleshooting: Socket message routing errors (incorrect socketId mapping). DB write/read errors. API authorization issues. Real-time updates not working (check socket listeners on client). Unread count logic errors.

STOP & CHECK: Users can send and receive private messages in real-time (if online), message history is stored persistently, and users can view conversation lists and message history via the client UI.

9.2 Player Feed (Simple Posts)

Step 1: Database Schema (Off-Chain): Create Posts table/collection : id, authorId (FK to User), contentText (limit length), timestamp, likeCount. Potentially parentPostId for replies later.

Step 2: Backend API Endpoints:

POST /api/feed/posts: Receives { contentText }. Requires authenticated user. Create new Post record with authorId = loggedInUserId, content, timestamp. Return created post.

GET /api/feed/posts: Fetch list of posts (paginate, order by timestamp descending). Potentially filter (e.g., posts by people user follows - requires follow system later). Include author info (username, avatar URI fetched via join/lookup).

POST /api/feed/posts/{postId}/like: Requires authenticated user. Increment likeCount on the Post record (handle potential race conditions or use atomic increment). Need to track who liked (separate Likes table?) to prevent double-liking.

DELETE /api/feed/posts/{postId}: Requires authenticated user is author. Delete post.

Step 3: Client UI (Feed Component):

Display list of posts fetched from GET /api/feed/posts. Show author name/avatar, content, timestamp, like count, like button, delete button (if author).

Include a text input area and "Post" button that calls POST /api/feed/posts. Update feed locally or refetch after successful post.

Implement "Like" button functionality calling POST .../like endpoint. Update like count locally.

Implement "Delete" button functionality calling DELETE ... endpoint. Remove post locally.

Why: Provides a simple social feed for players to share updates, comments, or achievements, fostering community engagement within the platform.

Tip: Implement pagination for fetching feed posts. Add basic content moderation checks or reporting for posts if needed. Start without replies/following for simplicity. Ensure API authorization checks ownership for delete/like actions.

Unit Test: Call POST /api/feed/posts; verify post created in DB. Call GET /api/feed/posts; verify new post appears with correct author info. Call POST .../like; verify like count increments in DB and API response. Call DELETE ...; verify post removed from DB. Test authorization (cannot delete/like other's posts unless allowed). Check client UI renders feed, handles posting, liking, deleting correctly.

Troubleshooting: API errors (DB access, authorization). Pagination logic errors. Like count race conditions (use atomic DB operations). Client UI update issues after actions.

STOP & CHECK: Users can create simple text posts, view a feed of posts, like posts, and delete their own posts via API calls and a functional client UI component.

9.3 Leaderboards & Profiles UI (Refinement)

Step 1: Leaderboard UI: Create dedicated Leaderboard page/component in client UI.

Add tabs/filters for different leaderboards: Overall Site (ELO), Per-Game W/L or ELO (requires tracking stats per game mode).

Call relevant backend API endpoint (e.g., /api/leaderboard/elo, /api/leaderboard/fps_1v1/wins) which should query the appropriate data source (Redis cache for ELO, potentially aggregated stats from match history DB for per-game).

Display ranked list: Rank, Player Name (linked to profile), Rating/Score. Implement pagination.

Step 2: Profile UI Enhancements: Improve the Player Profile page (from 7.2.1):

Add Match History section: Call backend API endpoint GET /api/player/{playerId}/matches which fetches data from the MongoDB matches collection (paginated). Display recent matches (opponent, game, result, date).

Add Achievements section: Integrate the UI for displaying achievement progress/completion (from 7.2.3).

Add Owned/Listed NFTs section: Display NFTs owned by the profile owner (fetch via Solana getTokensByOwner or indexer) and NFTs listed for sale by them (from marketplace data). Link to marketplace buy/details.

Add link to "Send Private Message". Add "Follow" button (if follow system implemented later).

Why: Makes leaderboards and player profiles central hubs for competitive comparison, tracking progress, viewing history, managing personalization, and initiating social interaction.

Tip: Ensure backend APIs for leaderboards and match history are efficient and paginated. Cache leaderboard data aggressively. Keep profile page loading performant by fetching data sections progressively if needed.

Unit Test: Navigate to Leaderboard page; verify ELO leaderboard fetches and displays correctly ranked data. Verify per-game leaderboard fetches/displays data (requires per-game stats tracking). Navigate to Profile page; verify match history list populates from API. Verify achievements section works. Verify NFT sections display correct owned/listed items. Verify links/buttons work.

Troubleshooting: API endpoint errors (slow queries, incorrect data). Client UI rendering/pagination bugs. Data consistency between leaderboards, profiles, and actual game results. Links not working.

STOP & CHECK: Dedicated Leaderboard UI displays rankings correctly. Player Profile UI is enhanced with match history, achievements, NFT display, and links to social actions.

This concludes Part 3. The core functionalities are now mostly implemented:

NFTs are created, distributed, and linked to players.

The platform can sell its initial NFT allocation.

Match fees are collected and distributed to NFT holders.

Dynamic NFT metadata reflects earnings/stats.

Basic private messaging and a public feed are functional.

Leaderboards and profiles are more comprehensive.

Okay, here is Part 4 of the detailed plan for the Solana Gaming Platform. This part focuses on completing the remaining core features like additional games, the peer-to-peer NFT marketplace with royalty considerations, advanced social features, and finalizing preparations for deployment.

Crucial Note on Royalties: Implementing creator royalties (player gets 10%, platform gets 2%) on secondary NFT sales (P2P trading) on Solana requires using the Metaplex Programmable NFT (pNFT) standard and potentially integrating with Metaplex-compliant marketplace protocols or building custom enforcement logic. Simple spl-token transfers bypass the older Metaplex Token Metadata royalty standard. We will plan based on using pNFTs and Metaplex tools.

Part 4: Additional Games, P2P Marketplace, Advanced Social & Launch Readiness

Objective: Integrate the remaining planned games, implement a peer-to-peer NFT marketplace with royalty enforcement, add advanced social features, conduct final testing and security audits, and prepare for production deployment.

Phase 10: Integrating Additional Games

Goal: Adapt and integrate the other planned game modes into the existing platform architecture.

10.1 Game Logic Adaptation (Per Game)

Step 1: Analyze Game Requirements: For each new game (e.g., a strategy card game, a puzzle racer):

Identify core mechanics, win conditions, player inputs, necessary state synchronization.

Determine if real-time server simulation (like FPS) or turn-based logic is needed.

Estimate server resource needs (CPU, memory).

Identify specific assets required (models, sprites, sounds, card definitions).

Step 2: Develop/Adapt Game Server Logic: Create a new game instance script (e.g., server/src/gameInstance_cardGame.js) mirroring the structure used for the FPS game (from 5.1):

Initialize game-specific state and logic (card decks, game board, turn manager).

Set up Socket.io handlers for game-specific actions (DRAW_CARD, PLAY_CARD, END_TURN).

Implement authoritative game rules engine (validate moves, determine outcomes). No physics (Rapier) likely needed for card/puzzle games.

Integrate communication protocol (IPC/API) to report READY, MATCH_STARTED, MATCH_RESULT (winner/loser) to the Game Server Manager.

Integrate Solana interactions: Load authority keypair, call release_escrow upon match completion based on game outcome. Potentially call update_stats if tracking per-game stats on-chain.

Step 3: Develop/Adapt Game Client Logic: Create new React components (e.g., components/GameViewCardGame.tsx):

Initialize game-specific rendering (e.g., using React components for cards/board, maybe Pixi.js or a simpler 2D library instead of Three.js).

Connect to the specific game server instance via Socket.io.

Handle game-specific UI interactions (dragging cards, clicking buttons).

Send game-specific actions (DRAW_CARD, PLAY_CARD) via Socket.io.

Receive and render GAME_STATE updates (player hands, board state, turn indicator).

Step 4: Asset Handling: Place new game assets in apps/web/public/assets/<game_name>/. Ensure client components load them correctly.

Step 5: Platform Integration:

Update Game Server Manager to recognize the new gameType and spawn the correct script.

Update Matchmaking service/UI to allow queueing for the new game.

Update backend logic to handle results/stats for the new game mode.

Update Player Profile UI to potentially display stats for the new game.

Why: Extends the platform's offerings by integrating diverse game types while reusing the core infrastructure (matchmaking, server management, escrow, profile). Requires adapting both server logic and client UI for each specific game's mechanics.

Tip: Start with the simplest new game first. Abstract common server instance logic (startup, communication, Solana interaction) into shared modules reused by different game instance scripts. Ensure consistent result reporting format across all games.

Unit Test: For each new game: Test spawning its specific instance via Manager. Test client connecting and basic UI rendering. Test sending/receiving game-specific actions and state updates via Socket.io. Play through a full game loop; verify outcome determined correctly, results reported, escrow released. Check integration points (matchmaking queue, profile stats).

Troubleshooting: Game logic bugs specific to the new game. State synchronization issues. Server instance not spawning correct game type. Client UI bugs for new game rendering/interaction. Result reporting inconsistencies.

STOP & CHECK: Each additional planned game's server logic is packaged into a manageable instance, client UI components are created, and the game is integrated into the platform's matchmaking, server management, and results processing pipeline.

Phase 11: P2P NFT Marketplace & Royalties

Goal: Allow users to list their owned Player NFTs (#1-6) for sale and enable others to buy them, ensuring royalties are enforced for the original player and the platform.

11.1 Programmable NFT (pNFT) Setup & Minting Update

Step 1: Use Programmable NFTs: Modify the NFT Minting Service (from 7.1) to mint NFTs using the Programmable NFT (pNFT) standard from Metaplex. This standard has built-in support for enforcing rules, including royalties, via the Token Authorization Rules program.

Update Metaplex SDK usage: The metaplex.nfts().create() call needs to specify tokenStandard: TokenStandard.ProgrammableNonFungible.

Define Rule Set (Optional but Recommended): Create a Metaplex Token Authorization Rule Set associated with these NFTs during minting. This rule set can enforce royalty payments during transfers facilitated by compatible marketplace programs. Consult Metaplex documentation for creating and using rule sets. This adds complexity but is the robust way to enforce royalties.

Step 2: Royalty Configuration: Ensure the sellerFeeBasisPoints (total royalty percentage * 100) and creators array (with shares adding up to 100) are correctly set during the metaplex.nfts().create() call.

sellerFeeBasisPoints: 1200 (for 12% total royalty).

creators: [ { address: playerWalletAddress, share: 83 /* ~10% of sale */ }, { address: platformRoyaltyWalletAddress, share: 17 /* ~2% of sale */ } ]. Note: Shares must sum to 100. Calculate percentages based on the total royalty (12%): 10/12 = ~83%, 2/12 = ~17%. The platform needs a dedicated wallet to receive these royalties.

Why: pNFTs and Rule Sets are Metaplex's mechanism for enforcing on-chain rules like royalties during transfers, making them harder to bypass than the older Token Metadata standard's royalties. Setting creators and shares correctly ensures royalties are distributed according to plan by compatible programs.

Tip: Understand the pNFT standard and Token Authorization Rules program well. This significantly increases complexity compared to basic NFTs. Test royalty enforcement thoroughly.

Unit Test: Modify minting test (from 7.1) to mint pNFTs. Inspect the created NFT's on-chain data using tools like Solana Explorer or Metaplex read APIs; verify tokenStandard is ProgrammableNonFungible, sellerFeeBasisPoints is correct, and creators array has correct addresses and shares.

Troubleshooting: Metaplex SDK errors related to pNFT creation or rule sets. Incorrect royalty configuration on-chain. Understanding pNFT transfer mechanics.

STOP & CHECK: NFT minting process is updated to create Programmable NFTs (pNFTs) with correct royalty configuration (player 10%, platform 2%) set in the on-chain metadata.

11.2 NFT Listing Logic (P2P)

Step 1: Define Listing Mechanism: Choose how P2P listings are managed:

Option A (Off-Chain Listings, On-Chain Settlement): Users signal intent to list via API. Backend tracks listings. When a buyer accepts, backend constructs the atomic swap transaction (SOL payment, NFT transfer, royalty distribution) using a standard protocol like Metaplex Auction House or a custom escrow. Simpler backend, relies on standard protocols or careful custom implementation.

Option B (On-Chain Listing Escrow): User calls a Solana program instruction to list, transferring their NFT into a program-controlled escrow account (PDA). The program stores the listing price. Buyers call another instruction to deposit SOL and claim the NFT. Program handles atomic swap and royalties. More decentralized, more complex program logic.

Recommendation: Start with Option A (Off-Chain Listings) using Metaplex Auction House program for settlement, as it's a well-audited standard for P2P sales with royalty enforcement.

Step 2: Integrate Metaplex Auction House (Backend Service):

Add Metaplex Auction House client library/helpers to a backend service (e.g., marketplace API).

This service needs access to a Platform Fee Payer Keypair (pays transaction fees for creating listings/sales on behalf of users sometimes, or structures tx for user to pay).

Step 3: API Endpoint (POST /api/marketplace/list):

Client sends { nftMintAddress, priceSOL }. User must own the NFT.

Backend verifies ownership (metaplex.nfts().findByMint...).

Backend uses Metaplex SDK to construct the transaction(s) needed to list the NFT on a platform-managed Metaplex Auction House instance. This typically involves the user signing a transaction to delegate authority or approve the Auction House program to sell the NFT on their behalf at the specified price.

Return the transaction(s) (serialized, base64) for the user to sign via their wallet.

Step 4: Client Listing Flow:

User clicks "List" on an owned NFT in their profile/inventory. Enters price.

Client calls POST /api/marketplace/list.

Receives transaction(s), signs via wallet, sends to Solana.

Provide UI feedback on listing success/failure.

Step 5: Update GET /api/marketplace/listings: Modify this endpoint to also query the Metaplex Auction House program state (or a cache updated by listening to Auction House events) to find NFTs listed by users, in addition to the platform-held NFTs (#4-6 which might also be listed via Auction House). Include seller address and listing price.

Why: Enables users to sell their earned/bought NFTs. Using a standard protocol like Auction House handles the complex atomic swap (SOL for NFT) and royalty distribution logic securely and in a way compatible with the ecosystem. Off-chain listing tracking is simpler than full on-chain escrow.

Tip: Understand Metaplex Auction House setup and interactions thoroughly. It involves creating an Auction House instance, treasury accounts, and handling various instructions (Sell, Buy, ExecuteSale). The backend acts as a facilitator, constructing transactions for users to sign.

Unit Test: Use Metaplex SDK/Anchor client in backend tests. Simulate client calling /list API. Verify backend constructs correct Auction House listing transaction(s). Simulate client signing and sending. Use Metaplex read APIs or Explorer to verify the NFT is now listed for sale on the Auction House at the correct price. Update /listings API test to verify it now includes user-listed items.

Troubleshooting: Auction House instruction errors (incorrect accounts, funds, authorities). Transaction construction complexity. Client signing issues. Querying Auction House state effectively. Handling listing cancellations.

STOP & CHECK: Users can initiate listing their owned Player NFTs via the UI, the backend constructs the necessary Metaplex Auction House listing transaction(s), the user signs, and the NFT becomes available for sale on the platform's Auction House instance, visible via the listings API.

11.3 NFT Buying Logic (P2P)

Step 1: API Endpoint (POST /api/marketplace/buy_p2p - or merge with existing buy):

Receive { listingNftMintAddress, buyerWalletAddress }.

Backend fetches listing details from Auction House state (seller, price). Verify listing is still active.

Backend uses Metaplex SDK Auction House client to construct the buy and executeSale transaction(s). executeSale is the core instruction that handles the atomic swap: transferring SOL from buyer to seller (less royalties), transferring NFT from seller (via Auction House authority) to buyer, and distributing royalties to creator addresses (player/platform) based on the pNFT's on-chain royalty configuration.

Return the transaction(s) (serialized, base64) for the buyer to sign.

Step 2: Client Buying Flow:

User clicks "Buy" on a user-listed NFT.

Client calls /api/marketplace/buy_p2p.

Receives transaction(s). Signs via wallet. Sends to Solana.

Confirm transaction. Provide UI feedback. Update UI to reflect ownership change (remove listing, show in buyer's inventory).

Why: Completes the P2P marketplace loop. Leverages Auction House's audited executeSale instruction to handle the atomic swap and crucially, the on-chain royalty enforcement based on the pNFT configuration.

Tip: The executeSale instruction requires several accounts (buyer, seller, metadata, mint, token accounts, treasury accounts, authority, etc.). Ensure the backend correctly provides all necessary accounts to the SDK helper or constructs the instruction manually. The buyer needs sufficient SOL for the price + potential transaction fees.

Unit Test: List an NFT (from 11.2). Simulate a different user calling /buy_p2p API. Verify backend constructs correct buy/executeSale transaction(s). Simulate buyer signing and sending. Monitor transaction on Solana Explorer. Verify: NFT transferred to buyer, SOL (price - royalties) transferred to seller, Royalty SOL transferred to player creator wallet, Royalty SOL transferred to platform royalty wallet. Verify listing removed.

Troubleshooting: executeSale transaction failures (check all account inputs, balances, authorities, NFT delegation status). Royalty calculation/distribution errors within Auction House program (check pNFT config). UI not updating after purchase.

STOP & CHECK: Users can buy NFTs listed by other players, the backend facilitates this using Metaplex Auction House, and upon successful execution, the atomic swap occurs with royalties correctly distributed on-chain to the original player and the platform.

Phase 12: Advanced Social & Platform Polish

Goal: Enhance community features and add final polish to the platform before launch.

12.1 Following System & Feed Filtering

Step 1: Database Schema: Add Follows table/collection : id, followerId (FK to User), followingId (FK to User), timestamp. Unique constraint on (followerId, followingId).

Step 2: Backend API Endpoints:

POST /api/users/{userId}/follow: Requires authenticated user. Create Follows record where followerId = loggedInUserId, followingId = {userId}. Handle already following case.

DELETE /api/users/{userId}/follow: Requires authenticated user. Delete Follows record.

GET /api/users/{userId}/followers: Fetch list of users following {userId} (paginate).

GET /api/users/{userId}/following: Fetch list of users {userId} is following (paginate).

Modify GET /api/feed/posts: Add optional query parameter filter=following. If present, query Posts table joining/filtering by authors where authorId is in the logged-in user's following list.

Step 3: Client UI Integration:

Add "Follow" / "Unfollow" button on Player Profile pages. Button calls relevant API endpoints. Update button state based on follow status.

On the Feed page, add filter options (e.g., "All Posts", "Following"). When "Following" selected, call GET /api/feed/posts?filter=following.

Display follower/following counts on Profile page (call relevant APIs).

Why: Allows users to curate their social experience by following players they are interested in, making the feed more relevant and fostering connections. Standard social media feature.

Tip: Optimize feed queries, especially the 'following' filter (database indexing is key). Consider caching following lists.

Unit Test: User A follows User B via API/UI. Verify Follows record created. Verify follower/following counts update on profiles. Fetch feed with filter=following for User A; verify only posts from User B appear. User A unfollows B; verify record deleted, counts update, feed filter works correctly.

Troubleshooting: API errors (DB queries, authorization). Feed filtering logic incorrect. Follow counts inaccurate. UI state not updating correctly after follow/unfollow.

STOP & CHECK: Users can follow/unfollow other users, view follower/following lists, and filter the main feed to show only posts from users they follow.

12.2 Real-time Notifications (Optional but Recommended)

Step 1: Identify Notification Events: List events users should be notified about in real-time: New Private Message, New Follower, Post Liked, Post Reply (if added), NFT Sold, Fees Received, Match Found, Friend Joined Game (if friend system added).

Step 2: Backend Logic & Delivery:

When a notifiable event occurs in the backend (e.g., new message saved, follow record created, NFT sale processed via listener/webhook):

Identify the recipient userId.

Check if user is currently connected to the main platform Socket.io server (using userId -> socketId mapping).

If connected, emit a NOTIFICATION event via Socket.io to their socketId: io.to(recipientSocketId).emit(MessageType.NOTIFICATION, { type: 'new_message', text: 'UserX sent you a message', link: '/chat/conversationX' });.

(Optional) Persistent Notifications: Store notifications in a Notifications DB table as well, so users who are offline can see them upon next login. Add isRead flag.

Step 3: Client UI Handling:

Listen for NOTIFICATION socket event.

Display a temporary toast/pop-up notification.

Update an unread notification count indicator (e.g., bell icon in header).

(If using persistent storage) Provide a dedicated Notifications page/dropdown fetching unread/recent notifications from a /api/notifications endpoint. Mark notifications as read when viewed/clicked.

Why: Improves user engagement and responsiveness by providing immediate feedback about relevant social or game events without requiring page refreshes or manual checking.

Tip: Keep notification payloads small. Provide links within notifications to relevant content. Allow users to configure notification preferences later. Use background queues for generating/sending notifications if logic is complex.

Unit Test: Trigger a notifiable event (e.g., send PM while recipient online). Verify recipient client receives NOTIFICATION socket event and displays toast. Log out recipient, trigger event, log back in; verify notification is available via API/persistent store if implemented. Test different notification types.

Troubleshooting: Socket messages not delivered (check connection status, socketId mapping). Persistent notifications not saving/retrieving correctly. UI display bugs for toasts or notification lists. Missing notifications for certain events.

STOP & CHECK: Real-time notifications are implemented for key events (e.g., new message, new follower), delivered via Socket.io to online users, potentially with persistent storage for offline viewing.

12.3 UI/UX Polish & Final Content

Step 1: Comprehensive UI Review: Go through every page and user flow in the application. Check for:

Consistent design language (styles, components, spacing).

Clarity and intuitiveness of navigation and interactions.

Responsiveness on all target devices (desktop, tablet, mobile).

Loading states (show spinners/skeletons while data fetches).

Error handling (display user-friendly messages for API errors, transaction failures, etc.).

Accessibility (ARIA attributes, keyboard navigation, color contrast).

Step 2: Add Final Content: Ensure all static text, help sections, FAQs, terms of service, privacy policy are written and integrated. Add branding (logo, color scheme).

Step 3: Performance Polish: Re-run frontend performance audits (Lighthouse in browser dev tools). Optimize image loading (lazy loading, modern formats like WebP/AVIF), reduce bundle sizes (code splitting), minimize layout shifts, improve Largest Contentful Paint (LCP) and First Input Delay (FID).

Step 4: Cross-Browser Testing: Test the application thoroughly on major target browsers (Chrome, Firefox, Safari, Edge).

Why: Creates a professional, trustworthy, and enjoyable user experience, which is crucial for user retention and platform credibility, especially when real money (SOL) and valuable assets (NFTs) are involved. Addresses accessibility and ensures broad compatibility.

Tip: Gather feedback from test users. Use analytics to identify confusing or underused parts of the UI. Prioritize clarity and ease of use, especially for complex flows like betting and NFT transactions.

Unit Test: Manual testing across flows, devices, and browsers. Use Lighthouse/PageSpeed Insights to score performance and accessibility; address recommendations. Validate error messages appear correctly for simulated failures.

Troubleshooting: CSS bugs, layout issues on specific browsers/devices. Poor performance scores. Unclear error messages. Accessibility violations. Inconsistent styling.

STOP & CHECK: The entire application UI/UX has been reviewed and polished for consistency, usability, responsiveness, performance, accessibility, and cross-browser compatibility. All necessary static content is in place.

Phase 13: Testing, Security Audit & Deployment

Goal: Ensure the platform is secure, stable, and ready for a production launch on Solana Mainnet.

13.1 End-to-End Testing

Step 1: Develop Test Plan: Create a comprehensive E2E test plan covering all major user flows: Registration -> Wallet Connect -> Profile Setup -> Finding Match (different games/bets) -> Depositing Escrow -> Playing Game -> Match Conclusion -> Escrow Release -> Fee Distribution -> Stat/Profile Update -> NFT Listing -> NFT Buying -> Social Interactions (Messaging, Feed, Follow).

Step 2: Manual Testing: Execute the test plan manually with multiple test accounts/wallets on Devnet/Testnet environment mirroring production. Test edge cases, error conditions, concurrent interactions.

Step 3: Automated E2E Testing (Optional but Highly Recommended): Implement automated E2E tests using frameworks like Playwright or Cypress. These tests simulate user interactions in a real browser, interacting with the frontend, backend APIs, and potentially mock wallet interactions (or real wallets in controlled test environments). Automate core flows like login, queueing, checking balances, profile viewing.

Why: Verifies that all integrated components work together correctly from the user's perspective. Catches integration bugs and regressions that unit/integration tests might miss. Automated tests provide faster feedback during development and pre-deployment checks.

Tip: Focus automated E2E tests on critical paths. Manual testing is still needed for exploratory testing and UI/UX validation. Ensure test environment is reset between runs.

Unit Test: Execute the full manual test plan; verify all steps succeed without unexpected errors or data inconsistencies. Run automated E2E test suite; verify all tests pass.

Troubleshooting: E2E tests failing (identify if frontend, backend API, Solana program, or integration issue). Test environment instability. Flaky tests (require careful setup, waits, assertions).

STOP & CHECK: Comprehensive end-to-end testing (manual and ideally automated) has been performed, validating all core user flows and integrations across the platform.

13.2 Security Audit (Solana Programs & Backend)

Step 1: Identify Critical Components: Focus audit efforts on:

Solana Programs (Escrow, Profile): Especially logic involving fund transfers (release_escrow), authority checks, account validation, PDA derivation, potential re-entrancy or logic exploits.

Backend Services: API endpoints handling authentication, authorization, constructing Solana transactions, interacting with sensitive data (user info, session keys).

Key Management: How are server authority/treasury/distribution keypairs stored, accessed, and used?

Frontend Interaction: How are transactions prepared and signed? Input validation on frontend/backend.

Step 2: Internal Code Review: Conduct thorough internal peer reviews of all security-critical code, specifically looking for vulnerabilities identified in Step 1. Use static analysis tools for Rust (Clippy) and JavaScript (ESLint security plugins).

Step 3: Engage External Auditors (Highly Recommended for Mainnet): Hire reputable third-party security auditors specializing in Solana smart contracts and web application security. Provide them with codebases, architecture diagrams, and documentation. Allow sufficient time for the audit.

Step 4: Address Findings: Carefully review the auditors' findings. Prioritize and fix all critical and high-severity vulnerabilities. Re-test fixes. Potentially have auditors review the fixes.

Why: Essential for protecting user funds (SOL in escrow) and assets (NFTs), maintaining platform integrity, and building user trust. Smart contract bugs can lead to irreversible loss of funds. Web security flaws can lead to account compromise or platform manipulation. External audits provide an unbiased expert assessment. DO NOT LAUNCH ON MAINNET WITH REAL VALUE WITHOUT AN AUDIT.

Tip: Budget time and money for audits early in the project plan. Choose auditors with strong Solana experience. Be transparent and provide comprehensive information to auditors. Fix all significant findings before launch.

Unit Test: (Audit is the test). Track audit findings. Verify fixes are implemented correctly and address the root cause. Confirm re-testing or auditor review validates the fixes. Maintain audit report.

Troubleshooting: Audit identifies major architectural flaws requiring significant rework. Difficulty fixing complex vulnerabilities. Disagreements with auditor findings (require discussion and evidence).

STOP & CHECK: Security-critical components (especially Solana programs and backend transaction handling) have undergone thorough internal review and, critically, a professional third-party security audit. All significant vulnerabilities identified have been addressed and verified.

13.3 Production Deployment & Go-Live Strategy

Step 1: Prepare Production Environment: Set up identical infrastructure (Kubernetes clusters, DBs, Redis, Load Balancers, Monitoring) in the production environment / mainnet region(s). Configure DNS, SSL certificates, firewalls.

Step 2: Mainnet Program Deployment: Deploy the audited Solana programs (Escrow, Profile) to Solana Mainnet-beta. Double-check all program IDs, authorities, and initial states. This is irreversible.

Step 3: Configuration Management: Finalize production configurations (environment variables, secrets) for all backend services and the Next.js app (API keys, database URLs, Solana cluster endpoint set to mainnet-beta, mainnet program IDs, secure keypair access). Use a secure secrets management system (cloud provider secrets manager, HashiCorp Vault).

Step 4: Deployment Pipeline (CI/CD): Configure the CI/CD pipeline (from 1.1.3) for production deployments. Include steps for building production Docker images, pushing to registry, deploying to production Kubernetes cluster using rolling updates or blue/green strategies. Add manual approval gates for production deployment.

Step 5: Data Migration (If needed): If test data needs clearing or initial setup data (e.g., platform config) needs seeding in production DBs, prepare migration scripts.

Step 6: Go-Live Plan: Define launch sequence: Deploy backend -> Deploy frontend -> Monitor initial traffic -> Announce launch. Have rollback plan ready. Ensure team is on standby for monitoring and incident response.

Step 7: Post-Launch Monitoring: Closely monitor dashboards and alerts (from 7.3.3) immediately after launch and ongoing. Track key business metrics (user signups, matches played, volume). Collect user feedback. Plan for patches and updates.

Why: Ensures a smooth, secure, and controlled transition from development/testing to a live production environment accessible by real users with real value on Solana Mainnet. Minimizes launch day issues and prepares for ongoing operation.

Tip: Perform a final deployment rehearsal to staging environment. Launch during off-peak hours initially if possible (beta launch). Communicate clearly with the team during deployment. Have incident response roles defined.

Unit Test: Deploy audited programs to Mainnet. Deploy full application stack to production environment via CI/CD pipeline. Perform smoke tests on production (connect wallet, view pages, attempt basic actions). Monitor production dashboards for errors or anomalies. Execute rollback plan in staging to test it.

Troubleshooting: Production deployment failures (config errors, permission issues, infrastructure problems). Unexpected errors or performance issues on Mainnet. Solana Mainnet congestion impacting transactions. Security incidents.

STOP & CHECK: Audited Solana programs deployed to Mainnet. Production infrastructure configured and deployed via CI/CD. Final configurations and secrets are secure. Go-live plan, monitoring, and incident response strategy are in place. Platform is live and operational.

This completes the 4-part detailed plan. It covers the architecture from foundational setup through game integration, Solana interactions, NFT systems, social features, and final launch preparations, emphasizing security and scalability best practices within the specified tech stack. Remember the timeline constraint makes this exceptionally challenging, requiring ruthless prioritization and potentially descoping features for an initial launch.

